#!/bin/sh

#!/bin/bash -e
#SBATCH -p tgac-medium # partition (queue)
#SBATCH -N 1 # number of nodes
#SBATCH -n 1 # number of tasks
#SBATCH --mem 8000 # memory pool for all cores
#SBATCH -t 3-23:59 # time (D-HH:MM)
#SBATCH -o slurm.%N.%j.out # STDOUT
#SBATCH -e slurm.%N.%j.err # STDERR
#SBATCH --mail-type=ALL # notifications for job done & fail
#SBATCH --mail-user=Tarang.Mehta@earlham.ac.uk # send-to address

################################################################################################################

# ATAC-seq pipeline - Part 3
# June 2020: Tarang K. Mehta, Earlham Institute, Norwich, UK

################################################################################################################

# Script usage: ./ATAC_Bioinf_pipeline_v2c.sh

## Place this script and the following files in $WD (created in first script)
# 1. As used in './ATAC_Bioinf_pipeline_v2a.sh': a 2-column space-delimited table where col1='R1/R2 filename's col2='desired species renamed filename: species_tissue_experiment e.g. Mz_L_ATAC/gDNA'
# 2. Scripts:
  # ATAC_Bioinf_pipeline_v2c_part3a.R
# 3. Run as an sbatch script with 8Gb memory and ~3 days runtime - will spawn off other jobs

################################################################################################################

# ~ This pipeline is ran for all ATAC narrow peak files generated by 'ATAC_Bioinf_pipeline_v2b.sh', and contains the following components:

# 1. IDR on all pairs of replicates (optional) - The IDR peaks are a subset of the naive overlap peaks that pass a specific IDR threshold of 10%.
# 	1a. IDR of true replicates
# 	1b. Compute Fraction of Reads in Peaks (FRiP) - bedtools and awk
# 2. Peak annotation - bedops and bioawk
# 	3a. TSS enrichment
# 	3b. Fraction of reads in annotated regions
# 3. TF footprinting and creation of signal tracks (needs to be ran on shifted BAM)- RGT (HINT-ATAC)
# 4. Differential analysis of peaks - Homer and DiffBind

################################################################################################################

# All variables are added (and can be amended) here

scripts=(/ei/projects/9/9e238063-c905-4076-a975-f7c7f85dbd56/data/ATACseq/3.run2) # place all scripts in the topmost directory - create this separately
# WD=(/ei/projects/9/9e238063-c905-4076-a975-f7c7f85dbd56/data/ATACseq/3.run2/$spID) # insert the working directory
email=Tarang.Mehta@earlham.ac.uk # SBATCH out and err send to address

### 1. IDR
idrdir=($scripts/1.IDR) # assign raw reads dir
prefixATAC=($scripts/prefixATAC.txt)
prefixpairs=($idrdir/prefixpairs.txt)
idrpairs=($idrdir/idrpairpaths.txt)
idrpair1=($idrdir/idrpairpaths_rep1.txt)
idrpair2=($idrdir/idrpairpaths_rep2.txt)
idrprefix=($idrdir/idrprefix.txt)
idrpair1a=($idrdir/idrpairpaths_rep1unzipped.txt) # unzipped narrow peaks file path for rep1
idrpair2a=($idrdir/idrpairpaths_rep2unzipped.txt) # unzipped narrow peaks file path for rep2
IDR_THRESH=0.1 # consider changing to 0.05
IDR_THRESH_TRANSFORMED=$(awk -v p=${IDR_THRESH} 'BEGIN{print -log(p)/log(10)}')
npeaks_idr=($idrdir/idr_10thresh_peakcount.txt) # Number of peaks passing IDR thresholds of 10%
npeaks_idrrep1=($idrdir/idr_10thresh_peakcount_rep1.txt) # Number of peaks passing IDR thresholds of 10% for replicate 1
npeaks_idrrep2=($idrdir/idr_10thresh_peakcount_rep2.txt) # Number of peaks passing IDR thresholds of 10% for replicate 2

fripprefix=($idrdir/fripprefix.txt)
FRIP=($idrdir/FRiPvalues.txt)
PASS=0.3
ACCEPTABLE=0.2

### 2. Peak annotation - there are several variables in the section that will need amending
annotdir=($scripts/2.Annotation) # assign raw reads dir
prefixATAC2=($scripts/prefixATAC2.txt)
atacqcscript=(ATAC_Bioinf_pipeline_v2c_part3a.R)

speciesid1=Mz
speciesid2=Pn
speciesid3=Ab
speciesid4=Nb
speciesid5=On
speciesid6=Ac

atacqcscript2=(ATAC_Bioinf_pipeline_v2c_part3b.sh) # this will be created in this script so do not need it

### 3. TF footprinting and creation of signal tracks
tffprdir=$scripts/3.TFfprint_SignalTrack
mkdir -p $tffprdir # make the directory here as files will be added
cd $tffprdir
## AS OF 25/06 - WHEN MOVED TO EI PROJECTS, REPLACE PATHS
# genome folders - the variables are obviously hardcoded below, if you want to make generic then create a for loop over species genomes in scripts
genomesdir=($scripts/genomes)
Mzg=($genomesdir/Mzebra)
Png=($genomesdir/Pnyererei)
Abg=($genomesdir/Aburtoni)
Nbg=($genomesdir/Nbrichardi)
Ong=($genomesdir/Oniloticus)
Acg=($genomesdir/Acalliptera)

# genome fasta - assign genomes here with FA* variables, and a list of paths will be created for while loops (so for adding own or other species, just change or add to variables here)
# NOTE: ensure input FASTAs have only a short headers e.g. >chr1 or >scaffold001 etc.
FAMzg=$Mzg/dna/Maylandia_zebra.M_zebra_UMD2a.dna.primary_assembly.allLG.fa
FAPng=$Png/dna/Pundamilia_nyererei.PunNye1.0.dna.nonchromosomal.fa
FAAbg=$Abg/dna/Haplochromis_burtoni.AstBur1.0.dna.nonchromosomal.fa
FANbg=$Nbg/dna/Neolamprologus_brichardi.NeoBri1.0.dna.nonchromosomal.fa
FAOng=$Ong/dna/Oreochromis_niloticus.O_niloticus_UMD_NMBU.dna.primary_assembly.allLG.fa
FAAcg=$Acg/dna/Astatotilapia_calliptera.fAstCal1.2.dna.primary_assembly.allLG.fa
genfastas=(path_genomes.txt)
for gf in "${!FA@}"; do
  # echo "$gf is set to ${!gf}"
  echo "${!gf}" >> $genfastas
done
# chromosome sizes - the variables are obviously hardcoded below, if you want to make generic then create a for loop over species genomes in scripts
Mzgchr=$Mzg/dna/Maylandia_zebra.M_zebra_UMD2a.dna.primary_assembly.allLG.fa.chrom.sizes
Pngchr=$Png/dna/Pundamilia_nyererei.PunNye1.0.dna.nonchromosomal.fa.chrom.sizes
Abgchr=$Abg/dna/Haplochromis_burtoni.AstBur1.0.dna.nonchromosomal.fa.chrom.sizes
Nbgchr=$Nbg/dna/Neolamprologus_brichardi.NeoBri1.0.dna.nonchromosomal.fa.chrom.sizes
Ongchr=$Ong/dna/Oreochromis_niloticus.O_niloticus_UMD_NMBU.dna.primary_assembly.allLG.fa.chrom.sizes
Acgchr=$Acg/dna/Astatotilapia_calliptera.fAstCal1.2.dna.primary_assembly.allLG.fa.chrom.sizes
# annotation files •.gtf - assign annotations here with annot* variables, and a list of paths will be created for while loops (so for adding own or other species, just change or add to variables here)
annotMzg=$Mzg/current_gtf/maylandia_zebra/Maylandia_zebra.M_zebra_UMD2a.101.gtf
annotPng=$Png/current_gtf/pundamilia_nyererei/Pundamilia_nyererei.PunNye1.0.101.gtf
annotAbg=$Abg/current_gtf/haplochromis_burtoni/Haplochromis_burtoni.AstBur1.0.101.gtf
annotNbg=$Nbg/current_gtf/neolamprologus_brichardi/Neolamprologus_brichardi.NeoBri1.0.101.gtf
annotOng=$Ong/current_gtf/oreochromis_niloticus/Oreochromis_niloticus.O_niloticus_UMD_NMBU.101.gtf
annotAcg=$Acg/current_gtf/astatotilapia_calliptera/Astatotilapia_calliptera.fAstCal1.2.101.gtf
antfiles=(path_annot.txt)
for af in "${!annot@}"; do
  # echo "$af is set to ${!af}"
  echo "${!af}" >> $antfiles
done
processggenaltsv2=(processggenaltsvpath2.txt)
# gene regions •.bed
MzggenGC=$Mzg/current_gtf/maylandia_zebra/Maylandia_zebra.M_zebra_UMD2a.101.generegions_Gencode.bed
PnggenGC=$Png/current_gtf/pundamilia_nyererei/Pundamilia_nyererei.PunNye1.0.101.generegions_Gencode.bed
AbggenGC=$Abg/current_gtf/haplochromis_burtoni/Haplochromis_burtoni.AstBur1.0.101.generegions_Gencode.bed
NbggenGC=$Nbg/current_gtf/neolamprologus_brichardi/Neolamprologus_brichardi.NeoBri1.0.101.generegions_Gencode.bed
OnggenGC=$Ong/current_gtf/oreochromis_niloticus/Oreochromis_niloticus.O_niloticus_UMD_NMBU.101.generegions_Gencode.bed
AcgenGC=$Acg/current_gtf/astatotilapia_calliptera/Astatotilapia_calliptera.fAstCal1.2.101.generegions_Gencode.bed
MzggenRS=$Mzg/current_gtf/maylandia_zebra/Maylandia_zebra.M_zebra_UMD2a.101.generegions_RefSeq.bed
PnggenRS=$Png/current_gtf/pundamilia_nyererei/Pundamilia_nyererei.PunNye1.0.101.generegions_RefSeq.bed
AbggenRS=$Abg/current_gtf/haplochromis_burtoni/Haplochromis_burtoni.AstBur1.0.101.generegions_RefSeq.bed
NbggenRS=$Nbg/current_gtf/neolamprologus_brichardi/Neolamprologus_brichardi.NeoBri1.0.101.generegions_RefSeq.bed
OnggenRS=$Ong/current_gtf/oreochromis_niloticus/Oreochromis_niloticus.O_niloticus_UMD_NMBU.101.generegions_RefSeq.bed
AcgenRS=$Acg/current_gtf/astatotilapia_calliptera/Astatotilapia_calliptera.fAstCal1.2.101.generegions_RefSeq.bed
# assign the species you require for downloading BioMart gene alias annotations here - for my pipeline there are five species (but only four have biomart entries - for other species, check the biomart identifier for the database e.g. mzebra_gene_ensembl, and amend below)
# this will then use the variables below to add to a file 'biomart_sp.txt' - this will then be read, line by line to download and process the biomart databases
sp1=mzebra_gene_ensembl
sp2=pnyererei_gene_ensembl
sp3=hburtoni_gene_ensembl
#sp4=nbrichardi_gene_ensembl
sp5=oniloticus_gene_ensembl
sp6=acalliptera_gene_ensembl
biomartspecies=(biomart_sp.txt)
for var in "${!sp@}"; do
  # echo "$var is set to ${!var}"
  echo "${!var}" >> $biomartspecies
done
splitmeme=$scripts/split_meme.py # ensure split meme python script is in scripts folder (although this is supressed to run here!)
# tab delimited gene alias file - not required for pipeline but good for downstream analyses
Mzggenaltsv=$Mzg/current_gtf/maylandia_zebra/Maylandia_zebra.M_zebra_UMD2a.101.genealias.tsv
Pnggenaltsv=$Png/current_gtf/pundamilia_nyererei/Pundamilia_nyererei.PunNye1.0.101.genealias.tsv
Abggenaltsv=$Abg/current_gtf/haplochromis_burtoni/Haplochromis_burtoni.AstBur1.0.101.genealias.tsv
Nbggenaltsv=$Nbg/current_gtf/neolamprologus_brichardi/Neolamprologus_brichardi.NeoBri1.0.101.genealias.tsv
Onggenaltsv=$Ong/current_gtf/oreochromis_niloticus/Oreochromis_niloticus.O_niloticus_UMD_NMBU.101.genealias.tsv
Acggenaltsv=$Acg/current_gtf/astatotilapia_calliptera/Astatotilapia_calliptera.fAstCal1.2.101.genealias.tsv
# gene alias files *.txt
Mzggenal=$Mzg/current_gtf/maylandia_zebra/Maylandia_zebra.M_zebra_UMD2a.101.genealias.txt
Pnggenal=$Png/current_gtf/pundamilia_nyererei/Pundamilia_nyererei.PunNye1.0.101.genealias.txt
Abggenal=$Abg/current_gtf/haplochromis_burtoni/Haplochromis_burtoni.AstBur1.0.101.genealias.txt
Nbggenal=$Nbg/current_gtf/neolamprologus_brichardi/Neolamprologus_brichardi.NeoBri1.0.101.genealias.txt
Onggenal=$Ong/current_gtf/oreochromis_niloticus/Oreochromis_niloticus.O_niloticus_UMD_NMBU.101.genealias.txt
Acggenal=$Acg/current_gtf/astatotilapia_calliptera/Astatotilapia_calliptera.fAstCal1.2.101.genealias.txt
Usr='mehtat'
export PATH="$PATH:/hpc-home/mehtat/.local/bin/" # this is to run RGT (supress here and footprinting script in part D if not required)
processggenaltsv=(processggenaltsvpath.txt)
biomartfiles=(biomartfilepaths.txt)
removesp=(neolamprologus_brichardi)
genalpaths=(genealiaspaths.txt)
rgtdatapath=(~/rgtdata) # insert path to RGT data folder for where RGT installed
rgtidsp1='[MzebraUMD2a]'
rgtidsp2='[PunNye1.0]'
rgtidsp3='[AstBur1.0]'
rgtidsp4='[NeoBri1.0]'
rgtidsp5='[OniloticusUMD]'
rgtidsp6='[fAstCal1.2]'
rgtidsp1a='MzebraUMD2a'
rgtidsp2a='PunNye1.0'
rgtidsp3a='AstBur1.0'
rgtidsp4a='NeoBri1.0'
rgtidsp5a='OniloticusUMD'
rgtidsp6a='fAstCal1.2'
fpsp1=Mz
fpsp2=Pn
fpsp3=Ab
fpsp4=Nb
fpsp5=On
fpsp6=Ac
e=1 # amend this for subtraction from number of files for array (as array starts from 0) default=1
pwmsp1=mz
pwmsp2=pn
pwmsp3=ab
pwmsp4=nb
pwmsp5=on
pwmsp6=ac
j=7 # this is the preceding JOBID number (change this if required e.g. more or less than five species analysed, otherwise JOBIDs will be 'off' - will also then need to change within sbatch while loop and other proceeding JOBIDs)



### 4. Differential analysis of peaks



################################################################################################################

### 1. Irreproducible Discovery Rate (IDR) on MACS2 narrow peaks and FRiP

## It is worth following the ENCODE project’s “ATAC-seq Data Standards and Prototype Processing Pipeline” for replicated data on MACS2 peak calling:
  # Peak call with MACS2 > narrow peaks file > IDR on true replicates e.g. Ab5_L and Ab6_L: This is the dataset to use
    # IDR is A statistical procedure called the Irreproducible Discovery Rate (IDR) operates on the replicated peak set and compares consistency of ranks of these peaks in individual replicate/pseudoreplicate peak sets.
      # checks the reproducibility information from the duplicates using the IDR statistic
      # The basic idea is that if two replicates measure the same underlying biology, the most significant peaks, which are likely to be genuine signals, are expected to have high consistency between replicates, whereas peaks with low significance, which are more likely to be noise, are expected to have low consistency.
      # If the consistency between a pair of rank lists (peaks) that contains both significant and insignificant findings is plotted, a transition in consistency is expected
      # This consistency transition provides an internal indicator of the change from signal to noise and suggests how many peaks have been reliably detected - red being false, black being true
      # By fitting a bivariate rank distribuion, IDR finds a threshold to separate real peaks from noise
    # install idr locally: https://github.com/kundajelab/idr
      # wget https://github.com/kundajelab/idr/archive/2.0.4.zip
      # unzip 2.0.4.zip
      # cd idr-2.0.4/
      # ml gcc
      # ml zlib
      # python3 setup.py install
    # follow IDR details: https://docs.google.com/document/d/1f0Cm4vRyDQDu0bMehHD7P7KOMxTOP-HiNoIvL1VcBt8/edit#
      # set IDR_THRESH=0.1
    # If you have more than 2 true replicates select the longest peak list from all pairs that passes the IDR threshold.

## NOTE:
# 1. run IDR as an array for all replicate pairs
# 2. In cases where there are more than 2 true replicates select the longest peak list from all pairs that passes the IDR threshold.

mkdir -p $idrdir
cd $idrdir

# 1aA. create a 2-column tab delimited file that has all narrowpeak file paths of pairs to compare
# 1aB. split the above file into two files, one for each column
# 1aC. using an array by iterating through each line of the two 1-column files from above, do the following for each pair:
  # 1aCa. create a pooled-replicate narrowPeak file
  # 1aCb. run IDR on each pair and get peaks passing threshold
  # 1aCc. for cases where there are more than 2 true replicates, select the longest peak list from all pairs that passes the IDR threshold.

# =============================
# 1a. IDR of true replicates
# 1aA. Create IDR comparison pairs
# create a 2-column tab delimited file that has all narrowpeak file paths of pairs to compare
# =============================

for a in $(awk '{print $1}' $prefixATAC); do
  for b in $(awk '{print $1}' $prefixATAC); do
    # echo -e "$a\t$b"
    echo -e "$a\t$b" | awk '{if($1 != $2) print $1, $2;}' OFS='\t' | awk -F"_" '{if($2==$4) print $0}' |
    awk '{if (substr($1,1,2)==substr($2,1,2)) {print $0, "YES"} else if (substr($1,1,2)!=substr($2,1,2)) {print $0, "NO"}}' OFS='\t' |
    grep -v 'NO' | cut -f1,2 >> $prefixpairs.temp
  done
done

awk -F'\t' '!seen[$1>$2 ? $1 FS $2 : $2 FS $1]++' $prefixpairs.temp > $prefixpairs # this removes duplicate pairs that are simply in a different order
rm $prefixpairs.temp

awk '{print "/ei/projects/9/9e238063-c905-4076-a975-f7c7f85dbd56/data/ATACseq/3.run2/"$1"/5.peak_calling/"$1"_peaks.narrowPeak.gz","\t","/ei/projects/9/9e238063-c905-4076-a975-f7c7f85dbd56/data/ATACseq/3.run2/"$2"/5.peak_calling/"$2"_peaks.narrowPeak.gz"}' $prefixpairs | sed 's/ //g' > $idrpairs

# Run a file check to ensure the pairs exist and continue if they do, else, echo that they do not exist

while read -r r1 r2; do
  # echo "rep1 is $r1, rep2 is $r2"
  if test -f "$r1" && test -f "$r2"; then
    echo "$r1 and $r2 EXISTS"
    # =============================
    # 1aB. Separate the pairwise comparisons for an array
    # split the above file into two files, one for each column
    # =============================
    #
    cut -f1 $idrpairs > $idrpair1
    cut -f2 $idrpairs > $idrpair2
    paircount=$(wc -l $idrpairs | awk -F' ' '{print $1}') # assign variable for total number of pairs
    IDRarray=0-$(expr $paircount - 1) # number of pairs for the array starting from 0
    #
    # =============================
    # 1aC. Run the IDR analyses by iterating in an array
    # 1aCa. unzip files and create a pooled-replicate narrowPeak file
    # 1aCb. Perform IDR analysis.
      # Generate a plot and IDR output with additional columns including IDR scores.
    # 1aCc. Get peaks passing IDR threshold of 10%
    #
    while IFS= read -r i; do
      gunzip $i
    done < $idrpair1
    #
    while IFS= read -r i; do
      gunzip $i
    done < $idrpair2
    #
    sed 's/.gz//g' $idrpair1 > $idrpair1a
    sed 's/.gz//g' $idrpair2 > $idrpair2a
    #
    #
    echo '#!/bin/bash -e' > 1a.IDR.sh
    echo '#SBATCH -p tgac-short # partition (queue)' >> 1a.IDR.sh
    echo '#SBATCH -N 1 # number of nodes' >> 1a.IDR.sh
    echo '#SBATCH -n 1 # number of tasks' >> 1a.IDR.sh
    echo "#SBATCH --array=$IDRarray" >> 1a.IDR.sh
    echo '#SBATCH --mem-per-cpu 8000' >> 1a.IDR.sh
    echo '#SBATCH -t 0-00:45' >> 1a.IDR.sh
    echo '#SBATCH --mail-type=ALL # notifications for job done & fail' >> 1a.IDR.sh
    echo "#SBATCH --mail-user=$email # send-to address" >> 1a.IDR.sh
    echo '#SBATCH -o slurm.%N.%j.out # STDOUT' >> 1a.IDR.sh
    echo '#SBATCH -e slurm.%N.%j.err # STDERR' >> 1a.IDR.sh
    printf '\n' >> 1a.IDR.sh
    echo '# 1aC. Run the IDR analyses by iterating in an array' >> 1a.IDR.sh
    echo '# 1aCa. unzip files and create a pooled-replicate narrowPeak file' >> 1a.IDR.sh
    echo "mapfile -t idrrep1 < $idrpair1a" >> 1a.IDR.sh
    echo "mapfile -t idrrep2 < $idrpair2a" >> 1a.IDR.sh
    echo "awk '{print"' $1"_"$2}'"' $prefixpairs > $idrprefix" >> 1a.IDR.sh
    echo "mapfile -t idrprefix < $idrprefix" >> 1a.IDR.sh
    printf '\n' >> 1a.IDR.sh
    echo 'cat ${idrrep1[${SLURM_ARRAY_TASK_ID}]} ${idrrep2[${SLURM_ARRAY_TASK_ID}]} > ${idrprefix[${SLURM_ARRAY_TASK_ID}]}_peaks.narrowPeak' >> 1a.IDR.sh
    echo '# 1aCb. Perform IDR analysis.' >> 1a.IDR.sh
    echo '# Generate a plot and IDR output with additional columns including IDR scores.' >> 1a.IDR.sh
    echo 'srun idr --samples ${idrrep1[${SLURM_ARRAY_TASK_ID}]} ${idrrep2[${SLURM_ARRAY_TASK_ID}]} --peak-list ${idrprefix[${SLURM_ARRAY_TASK_ID}]}_peaks.narrowPeak --input-file-type narrowPeak --output-file ${idrprefix[${SLURM_ARRAY_TASK_ID}]}.IDR0.1output --rank p.value --soft-idr-threshold '"${IDR_THRESH} --plot --use-best-multisummit-IDR" >> 1a.IDR.sh
    echo '# 1aCc. Get peaks passing IDR threshold of 10%' >> 1a.IDR.sh
    echo '# IDR QC to report and using the IDR output' >> 1a.IDR.sh
    echo '# 1. For each biological replicate pair, filter the IDR peaks based on the ${IDR_THRESH_TRANSFORMED} and sort descending based on signal.value (col7)' >> 1a.IDR.sh
    printf '\n' >> 1a.IDR.sh
    echo "awk 'BEGIN{OFS="'"\t"} $12>='"'"${IDR_THRESH_TRANSFORMED}"' {print "'$1,$2,$3,$4,$5,$6,$7,$8,$9,$10}'"' "'${idrprefix[${SLURM_ARRAY_TASK_ID}]}.IDR0.1output | sort | uniq | sort -k7,7rn > ${idrprefix[${SLURM_ARRAY_TASK_ID}]}.IDR0.1Transf.narrowPeak' >> 1a.IDR.sh
    printf '\n' >> 1a.IDR.sh
    echo '# 2. For each biological replicate pair, count the number of lines passing ${IDR_THRESH_TRANSFORMED} - this is where IDR finds the threshold to separate real peaks from noise' >> 1a.IDR.sh
    echo 'wc -l ${idrprefix[${SLURM_ARRAY_TASK_ID}]}.IDR0.1Transf.narrowPeak >>'" $npeaks_idr # Number of peaks passing IDR thresholds of 10%" >> 1a.IDR.sh
    echo '# 3. For each biological replicate in a pair, assign the wc -l as max_numPeaks_Rep peaks' >> 1a.IDR.sh
    echo "awk -F'.' '{print "'$1}'"' $npeaks_idr | awk -F'_' '{print"' $1"_"$2"_"$3" "$4"_"$5"_"$6}'"' | sed 's/ /\t/g' > $npeaks_idr.tmp" >> 1a.IDR.sh
    echo "cut -f1,2 $npeaks_idr.tmp > $npeaks_idrrep1" >> 1a.IDR.sh
    echo "cut -f1,3 $npeaks_idr.tmp > $npeaks_idrrep2" >> 1a.IDR.sh
    echo '# cat $npeaks_idr.tmp2 $npeaks_idr.tmp3 | sort -k2,2 > $npeaks_idr2' >> 1a.IDR.sh
    echo "rm *tmp*" >> 1a.IDR.sh
    printf '\n' >> 1a.IDR.sh
    echo "# 4. For each biological replicate pair, sort the MACS2 narrowPeak file based on signal.value column (col7) and add another column on end 'max_numPeaks_Rep', adding 'T' for True and 'F' for False of peaks that pass IDR, based on wc -l" >> 1a.IDR.sh
    printf '\n' >> 1a.IDR.sh
    echo '# mapfile -t idrrep1 < $idrpair1a' >> 1a.IDR.sh
    echo '# mapfile -t idrrep2 < $idrpair2a' >> 1a.IDR.sh
    echo '# mapfile -t idrrep1peak < $npeaks_idrrep1' >> 1a.IDR.sh
    echo '# mapfile -t idrrep2peak < $npeaks_idrrep2' >> 1a.IDR.sh
    #
    #
    echo '#!/bin/bash -e' > 1aB.IDR.sh
    echo '#SBATCH -p tgac-short # partition (queue)' >> 1aB.IDR.sh
    echo '#SBATCH -N 1 # number of nodes' >> 1aB.IDR.sh
    echo '#SBATCH -n 1 # number of tasks' >> 1aB.IDR.sh
    echo '#SBATCH --mem-per-cpu 8000' >> 1aB.IDR.sh
    echo '#SBATCH -t 0-00:45' >> 1aB.IDR.sh
    echo '#SBATCH --mail-type=ALL # notifications for job done & fail' >> 1aB.IDR.sh
    echo "#SBATCH --mail-user=$email # send-to address" >> 1aB.IDR.sh
    echo '#SBATCH -o slurm.%N.%j.out # STDOUT' >> 1aB.IDR.sh
    echo '#SBATCH -e slurm.%N.%j.err # STDERR' >> 1aB.IDR.sh
    printf '\n' >> 1aB.IDR.sh
    echo '# Double while read array:' >> 1aB.IDR.sh
    echo '# 1. Read in the peak numbers and narrowPeak files and do an IF statement to match the corresponding files' >> 1aB.IDR.sh
    echo '# 2. sort peaks file based on col7 (signal value - fold-change at peak summit)' >> 1aB.IDR.sh
    echo '# 3. read from file paths, open; read from peaks' >> 1aB.IDR.sh
    echo '# 4. use number in col1 to add T to that line and all preceding lines and add F for all lines thereafter' >> 1aB.IDR.sh
    printf '\n' >> 1aB.IDR.sh
    echo 'while IFS= read -u 3 -r reppeak && IFS= read -u 4 -r npeak; do' >> 1aB.IDR.sh
    echo -e '\t# echo ${npeak}' >> 1aB.IDR.sh
    echo -e '\t# echo ${reppeak}' >> 1aB.IDR.sh
    echo -e '\tpeakline=$(echo ${npeak} | awk -F'"' ' '{print "'$1}'"') # get the total count of IDR passed peaks" >> 1aB.IDR.sh
    echo -e '\tpeakprefix=$(echo ${npeak} | awk -F'"' ' '{print "'$2}'"') # get the file prefix this corresponds to" >> 1aB.IDR.sh
    echo -e '\t# echo $peakline' >> 1aB.IDR.sh
    echo -e '\t# echo $peakprefix' >> 1aB.IDR.sh
    echo -e '\tout=$(echo $(basename ${reppeak}) | sed -e '"'s/.narrowPeak/.final.narrowPeak/') # create an outfile" >> 1aB.IDR.sh
    echo -e '\tinprefix=$(echo $(basename ${reppeak}) | sed -e '"'s/_peaks.narrowPeak//') # get the prefix of the narrow peak in file" >> 1aB.IDR.sh
    echo -e '\t# echo $out' >> 1aB.IDR.sh
    echo -e '\t# echo $inprefix' >> 1aB.IDR.sh
    echo -e '\tif [[ $peakprefix = $inprefix ]]; then # check that the peaks passing IDR and narrowPeak file match' >> 1aB.IDR.sh
    echo -e '\t\t"peakcount>> $peakprefix = $inprefix <<narrowPeaks_file: npeaks and peaks file ARE matched"'
    echo -e '\t\tsort -k7,7rn ${reppeak} | awk -v peakline="$peakline" '"'{if(NR>=1 && NR<=peakline)print "'$0,"T";else print $0,"F";}'"' OFS='\t' > "'${out} # check with awk '"'FNR>=103003 && FNR<=103006'" >> 1aB.IDR.sh
    echo -e '\telse' >> 1aB.IDR.sh
    echo -e '\t\t"peakcount>> $peakprefix != $inprefix <<narrowPeaks_file: npeaks and peaks file NOT matched"' >> 1aB.IDR.sh
    echo -e '\tfi' >> 1aB.IDR.sh
    echo "done 3<$idrpair1a 4<$npeaks_idrrep1" >> 1aB.IDR.sh
  else
    echo "$r1 and/or $r2 DOES NOT EXIST"
  fi
done < idrpairpaths.txt


# IDR output
# Broad peak output files are the same except that they do not include the the summit columns (e.g. columns 10, 18, and 22 for samples with 2 replicates)
#
#     1. chrom string
#     Name of the chromosome for common peaks
#
#     2. chromStart int
#     The starting position of the feature in the chromosome or scaffold for common peaks, shifted based on offset. The first base in a chromosome is numbered 0.
#
#     3. chromEnd int
#     The ending position of the feature in the chromosome or scaffold for common peaks. The chromEnd base is not included in the display of the feature.
#
#     4. name string
#     Name given to a region (preferably unique) for common peaks. Use '.' if no name is assigned.
#
#     5. score int
#     Contains the scaled IDR value, min(int(log2(-125IDR), 1000). e.g. peaks with an IDR of 0 have a score of 1000, idr 0.05 have a score of int(-125log2(0.05)) = 540, and idr 1.0 has a score of 0.
#
#     6. strand [+-.] Use '.' if no strand is assigned.
#
#     7. signalValue float
#     Measurement of enrichment for the region for merged peaks. When a peak list is provided this is the value from the peak list.
#
#     8. p-value float
#     Merged peak p-value. When a peak list is provided this is the value from the peak list.
#
#     9. q-value float
#     Merged peak q-value. When a peak list is provided this is the value from the peak list.
#
#     10. summit int
#     Merged peak summit
#
#     11. localIDR float -log10(Local IDR value)
#
#     12. globalIDR float -log10(Global IDR value)
#
#     13. rep1_chromStart int
#     The starting position of the feature in the chromosome or scaffold for common replicate 1 peaks, shifted based on offset. The first base in a chromosome is numbered 0.
#
#     14. rep1_chromEnd int
#     The ending position of the feature in the chromosome or scaffold for common replicate 1 peaks. The chromEnd base is not included in the display of the feature.
#
#     15. rep1_signalValue float
#     Signal measure from replicate 1. Note that this is determined by the --rank option. e.g. if --rank is set to signal.value, this corresponds to the 7th column of the narrowPeak, whereas if it is set to p.value it corresponds to the 8th column.
#
#     16. rep1_summit int
#     The summit of this peak in replicate 1.
#
# [rep 2 data]
#
# ...
#
# [rep N data]


# The plot (*.IDR0.1output.png) for each quadrant is described below:
# Upper Left: Replicate 1 peak ranks versus Replicate 2 peak ranks - peaks that do not pass the specified idr threshold are colored red.
# Upper Right: Replicate 1 log10 peak scores versus Replicate 2 log10 peak scores - peaks that do not pass the specified idr threshold are colored red.
# Bottom Row: Peak rank versus IDR scores are plotted in black. The overlayed boxplots display the distribution of idr values in each 5% quantile. The IDR values are thresholded at the optimization precision - 1e-6 by default.

## FINAL PEAK FILES based on IDR QC are *.final.narrowPeak - the last column of T (True) or F (False) indicate peaks passing IDR

# =============================

echo '# -- 1a. IDR started -- #'

JOBID1=$( sbatch -W --array=$IDRarray 1a.IDR.sh | awk '{print $4}' ) # Run the first job and then store the first job to variable JOBID1 (taken by awk once run)

JOBID2=$( sbatch -W --dependency=afterok:${JOBID1} 1aB.IDR.sh | awk '{print $4}' ) # JOB2 depends on JOB1 completing successfully

# =============================

# 1b. Compute Fraction of Reads in Peaks (FRiP)
# The fraction of reads in called peak regions (FRiP score) should be >0.3, though values greater than 0.2 are acceptable.
# FRiP scores will not be enforced as QC metric. TSS enrichment remains in place as a key signal to noise measure.

# 1bA. Create a 3 column file - col1: variableID; col2: tagAlign input; col3: IDR peak file

echo '#!/bin/bash -e' > 1bA.FRIPawk.sh
echo '#SBATCH -p tgac-short # partition (queue)' >> 1bA.FRIPawk.sh
echo '#SBATCH -N 1 # number of nodes' >> 1bA.FRIPawk.sh
echo '#SBATCH -n 1 # number of tasks' >> 1bA.FRIPawk.sh
echo '#SBATCH --mem-per-cpu 4000' >> 1bA.FRIPawk.sh
echo '#SBATCH -t 0-00:45' >> 1bA.FRIPawk.sh
echo '#SBATCH --mail-type=ALL # notifications for job done & fail' >> 1bA.FRIPawk.sh
echo "#SBATCH --mail-user=$email # send-to address" >> 1bA.FRIPawk.sh
echo '#SBATCH -o slurm.%N.%j.out # STDOUT' >> 1bA.FRIPawk.sh
echo '#SBATCH -e slurm.%N.%j.err # STDERR' >> 1bA.FRIPawk.sh
printf '\n' >> 1bA.FRIPawk.sh
echo 'awk -F'"'\t' '{print "'$1,"/ei/projects/9/9e238063-c905-4076-a975-f7c7f85dbd56/data/ATACseq/3.run2/"$1"/5.peak_calling/"$1".tn5.tagAlign.gz",$1"_peaks.final.narrowPeak"}'"' OFS='\t' $prefixATAC > $fripprefix" >> 1bA.FRIPawk.sh


echo '# -- 1a. IDR has completed -- #'

echo '# -- 1b. FRiP calculation has started -- #'

JOBID3=$( sbatch -W --dependency=afterok:${JOBID2} 1bA.FRIPawk.sh | awk '{print $4}' ) # JOB3 depends on JOB2 completing successfully

echo '#!/bin/bash -e' > 1bB.FRIPok.sh
echo '#SBATCH -p tgac-short # partition (queue)' >> 1bB.FRIPok.sh
echo '#SBATCH -N 1 # number of nodes' >> 1bB.FRIPok.sh
echo '#SBATCH -n 1 # number of tasks' >> 1bB.FRIPok.sh
echo '#SBATCH --mem-per-cpu 1000' >> 1bB.FRIPok.sh
echo '#SBATCH -t 0-00:10' >> 1bB.FRIPok.sh
echo '#SBATCH --mail-type=ALL # notifications for job done & fail' >> 1bB.FRIPok.sh
echo "#SBATCH --mail-user=$email # send-to address" >> 1bB.FRIPok.sh
echo '#SBATCH -o slurm.%N.%j.out # STDOUT' >> 1bB.FRIPok.sh
echo '#SBATCH -e slurm.%N.%j.err # STDERR' >> 1bB.FRIPok.sh
printf '\n' >> 1bB.FRIPok.sh
echo 'FRiP calculation will start now...' >> 1bB.FRIPok.sh

JOBID4=$( sbatch -W --dependency=afterok:${JOBID3} 1bB.FRIPok.sh | awk '{print $4}' ) # JOB4 depends on JOB3 completing successfully

# 1bB. while read over the 3 column file and over each line
ml bedtools/2.25.0

while IFS=$'\t' read -r c1 c2 c3; do
  # assign variable for doing bedtools intersect of tagAlign and IDR
  val1=$(bedtools intersect -a <(zcat -f ${c2}) -b <(cat ${c3}) -wa -u | wc -l)
  # 1bC. For loop over the 3 column file and over each line, assigning variable.2 for wc -l over tagAlign file
  val2=$(zcat ${c2} | wc -l)
  # 1bD. For each pair of variables, calculate the FRiP value
  frac=$(bc -l <<< "(${val1}/${val2})")
  printf '%s\t%s\t%f\n' "$c1" "$val1""/""$val2" "$frac" >> $FRIP.temp
done < $fripprefix

while IFS=$'\t' read -r a b c; do
  if ((`bc <<< "${c}>=${PASS}"`));
  then printf '%s\t%s\t%f\t%s\n' "$a" "$b" "$c" "FRiP PASS" >> $FRIP
  elif ((`bc <<< "${c}>=${ACCEPTABLE}"`));
  then printf '%s\t%s\t%f\t%s\n' "$a" "$b" "$c" "FRiP PASS - acceptable" >> $FRIP
  else printf '%s\t%s\t%f\t%s\n' "$a" "$b" "$c" "FRiP FAIL" >> $FRIP
  fi
done < $FRIP.temp
rm $FRIP.temp

################################################################################################################

### 2. Annotation:
# 	2a. TSS enrichment - plot
  # The TSS enrichment calculation is a signal to noise calculation.
  # Fragments from the nucleosome-free regions (NFR) (< 100 bp) are expected to be enriched around the transcription start site (TSS) of genes, while fragments from nucleosome-bound regions e.g. mono-, di-, and tri-nucleosomes (~ 200, 400, 600 bp, respectively) are expected to be depleted at TSS with a slight enrichment of flanking regions around TSS. These can be evaluated with the tool ATACseqQC.
  # The reads around a reference set of TSSs are collected to form an aggregate distribution of reads centered on the TSSs and extending to 1000 bp in either direction (for a total of 2000bp).
  # This distribution is then normalized by taking the average read depth in the 100 bps at each of the end flanks of the distribution (for a total of 200bp of averaged data) and calculating a fold change at each position over that average read depth.
  # This means that the flanks should start at 1, and if there is high read signal at transcription start sites (highly open regions of the genome) there should be an increase in signal up to a peak in the middle.
  # We take the signal value at the center of the distribution after this normalization as our TSS enrichment metric.

# 	2b. Fraction of Reads in annotated regions - TO DO

#### Emailed CiS on 28/08/2020 to install R-4.0.2 with the required packages - they have done this: source /ei/software/staging/CISSUPPORT-11716/stagingloader
## Installed the following packages in R-4.0.2: "RMySQL","rtracklayer","GenomicFeatures","GLAD","gsl","ensembldb","GenomicRanges","MotIV","motifStack","ATACseqQC","ChIPpeakAnno", "MotifDb", "GenomicAlignments","Rsamtools","BSgenome","Biostrings","ggplot2","DiffBind", "DESeq2", "motifbreakR"


mkdir -p $annotdir
cd $annotdir


## 2a. Use ATACseqQC here (ensure input BAM is indexed) TO 1) CREATE A SHIFTED BAM, AND 2) RUN TSS ENRICHMENT
# For ATACseqQC we need to use BSgenome objects: Since we need to use custom genomes that are different to those available, forge a BSgenome package using bare sequences

## 2aA. Split a genome fasta into multiple .fa files (one for each scaffold)

# Create a file with col1 as species id and col2 as the input genome fasta to create a while loop for the genome split
splitg=(splitgenomes.txt)
echo -e "$speciesid1\t$FAMzg" >> $splitg
echo -e "$speciesid2\t$FAPng" >> $splitg
echo -e "$speciesid3\t$FAAbg" >> $splitg
echo -e "$speciesid4\t$FANbg" >> $splitg
echo -e "$speciesid5\t$FAOng" >> $splitg
echo -e "$speciesid6\t$FAAcg" >> $splitg

while read -r i1 i2; do
  mkdir $annotdir/$i1
  cd $annotdir/$i1
  awk -F "|" '/^>/ {close(F) ; F = substr($1,2,length($1)-1)".fa"} {print >> F}' $i2
done < $splitg # this while loop will make the species dirs, change into them and split the genome fasta by chr


## 2aB. Prepare the seedfiles to forge a BSgenome data package
cd $annotdir

### DO NOT MOVE THESE BS GENOME VARIABLES TO THE TOP AS IT NEEDS FILES RAN ABOVE
BSsp1a='Mzeb' # BSgenome package ID part 1
BSsp1b='M_zebra_UMD2a' # BSgenome package ID part 2
BSsp1c='Maylandia zebra' # Species name
BSsp1d='UMD2a' # Assembly version
BSsp1e='Ensembl' # Genome provider
BSsp1f='Apr. 2018' # Release date
BSsp1g='ftp://ftp.ensembl.org/pub/current_fasta/maylandia_zebra' # Source URL
BSsp1h='Maylandia_zebra' # Species_biocview
BSsp1i=`echo "paste(c($(echo ${speciesid1}_splitfasta/*.fa | sed "s/${speciesid1}_splitfasta\///g" | sed 's/.fa//g' | tr '\n' ' ' | sed 's/^/"/g' | sed 's/$/"/g' | sed 's/ /", "/g' | sed 's|, ""||g')))"` # an R expression for all the sequence names e.g. paste("chr", c(1:20, "X", "M", "Un", paste(c(1:20, "X", "Un"), "_random", sep="")), sep="")
BSsp1j="$annotdir/$speciesid1" # sequences dir

BSsp2a='Pnye' # BSgenome package ID part 1
BSsp2b='PunNye1.0' # BSgenome package ID part 2
BSsp2c='Pundamilia nyererei' # Species name
BSsp2d='1.0' # Assembly version
BSsp2e='Ensembl' # Genome provider
BSsp2f='Dec. 2011' # Release date
BSsp2g='ftp://ftp.ensembl.org/pub/current_fasta/pundamilia_nyererei' # Source URL
BSsp2h='Pundamilia_nyererei' # Species_biocview
BSsp2i=`echo "paste(c($(echo ${speciesid2}_splitfasta/*.fa | sed "s/${speciesid2}_splitfasta\///g" | sed 's/.fa//g' | tr '\n' ' ' | sed 's/^/"/g' | sed 's/$/"/g' | sed 's/ /", "/g' | sed 's|, ""||g')))"` # an R expression for all the sequence names e.g. paste("chr", c(1:20, "X", "M", "Un", paste(c(1:20, "X", "Un"), "_random", sep="")), sep="")
BSsp2j="$annotdir/$speciesid2" # sequences dir

BSsp3a='Abur' # BSgenome package ID part 1
BSsp3b='AstBur1.0' # BSgenome package ID part 2
BSsp3c='Astatotilapia burtoni' # Species name
BSsp3d='1.0' # Assembly version
BSsp3e='Ensembl' # Genome provider
BSsp3f='Dec. 2011' # Release date
BSsp3g='ftp://ftp.ensembl.org/pub/current_fasta/haplochromis_burtoni' # Source URL
BSsp3h='Astatotilapia_burtoni' # Species_biocview
BSsp3i=`echo "paste(c($(echo ${speciesid3}_splitfasta/*.fa | sed "s/${speciesid3}_splitfasta\///g" | sed 's/.fa//g' | tr '\n' ' ' | sed 's/^/"/g' | sed 's/$/"/g' | sed 's/ /", "/g' | sed 's|, ""||g')))"` # an R expression for all the sequence names e.g. paste("chr", c(1:20, "X", "M", "Un", paste(c(1:20, "X", "Un"), "_random", sep="")), sep="")
BSsp3j="$annotdir/$speciesid3" # sequences dir

BSsp4a='Nbri' # BSgenome package ID part 1
BSsp4b='NeoBri1.0' # BSgenome package ID part 2
BSsp4c='Neolamprologus brichardi' # Species name
BSsp4d='1.0' # Assembly version
BSsp4e='Ensembl' # Genome provider
BSsp4f='Dec. 2011' # Release date
BSsp4g='ftp://ftp.ensembl.org/pub/current_fasta/neolamprologus_brichardi' # Source URL
BSsp4h='Neolamprologus_brichardi' # Species_biocview
BSsp4i=`echo "paste(c($(echo ${speciesid4}_splitfasta/*.fa | sed "s/${speciesid4}_splitfasta\///g" | sed 's/.fa//g' | tr '\n' ' ' | sed 's/^/"/g' | sed 's/$/"/g' | sed 's/ /", "/g' | sed 's|, ""||g')))"` # an R expression for all the sequence names e.g. paste("chr", c(1:20, "X", "M", "Un", paste(c(1:20, "X", "Un"), "_random", sep="")), sep="")
BSsp4j="$annotdir/$speciesid4" # sequences dir

BSsp5a='Onil' # BSgenome package ID part 1
BSsp5b='O_niloticus_UMD_NMBU' # BSgenome package ID part 2
BSsp5c='Oreochromis niloticus' # Species name
BSsp5d='UMD_NMBU' # Assembly version
BSsp5e='Ensembl' # Genome provider
BSsp5f='Jun. 2018' # Release date
BSsp5g='ftp://ftp.ensembl.org/pub/current_fasta/oreochromis_niloticus' # Source URL
BSsp5h='Oreochromis_niloticus' # Species_biocview
BSsp5i=`echo "paste(c($(echo ${speciesid5}_splitfasta/*.fa | sed "s/${speciesid5}_splitfasta\///g" | sed 's/.fa//g' | tr '\n' ' ' | sed 's/^/"/g' | sed 's/$/"/g' | sed 's/ /", "/g' | sed 's|, ""||g')))"` # an R expression for all the sequence names e.g. paste("chr", c(1:20, "X", "M", "Un", paste(c(1:20, "X", "Un"), "_random", sep="")), sep="")
BSsp5j="$annotdir/$speciesid5" # sequences dir

BSsp6a='Acal' # BSgenome package ID part 1
BSsp6b='fAstCal1.2' # BSgenome package ID part 2
BSsp6c='Astatotilapia calliptera' # Species name
BSsp6d='1.2' # Assembly version
BSsp6e='Ensembl' # Genome provider
BSsp6f='Jul. 2018' # Release date
BSsp6g='ftp://ftp.ensembl.org/pub/current_fasta/astatotilapia_calliptera' # Source URL
BSsp6h='Astatotilapia_calliptera' # Species_biocview
BSsp6i=`echo "paste(c($(echo ${speciesid6}_splitfasta/*.fa | sed "s/${speciesid6}_splitfasta\///g" | sed 's/.fa//g' | tr '\n' ' ' | sed 's/^/"/g' | sed 's/$/"/g' | sed 's/ /", "/g' | sed 's|, ""||g')))"` # an R expression for all the sequence names e.g. paste("chr", c(1:20, "X", "M", "Un", paste(c(1:20, "X", "Un"), "_random", sep="")), sep="")
BSsp6j="$annotdir/$speciesid6" # sequences dir

speciesBSgenome1=BSgenome.Mzeb.Ensembl.M_zebra_UMD2a
speciesBSgenome2=BSgenome.Pnye.Ensembl.PunNye1.0
speciesBSgenome3=BSgenome.Abur.Ensembl.AstBur1.0
speciesBSgenome4=BSgenome.Nbri.Ensembl.NeoBri1.0
speciesBSgenome5=BSgenome.Onil.Ensembl.O_niloticus_UMD_NMBU
speciesBSgenome6=BSgenome.Acal.Ensembl.fAstCal1.2

echo "Package: BSgenome.$BSsp1a.$BSsp1e.$BSsp1b" > $BSsp1b.seedfile
echo "Title: Full genome sequences for $BSsp1c (version $BSsp1b)" >> $BSsp1b.seedfile
echo "Description: Full genome sequences for $BSsp1c as provided by $BSsp1e ($BSsp1b, $BSsp1f) and stored in Biostrings objects." >> $BSsp1b.seedfile
echo "Version: $BSsp1d" >> $BSsp1b.seedfile
echo "organism: $BSsp1c" >> $BSsp1b.seedfile
echo "common_name: $BSsp1c" >> $BSsp1b.seedfile
echo "provider: $BSsp1e" >> $BSsp1b.seedfile
echo "provider_version: $BSsp1b" >> $BSsp1b.seedfile
echo "release_date: $BSsp1f" >> $BSsp1b.seedfile
echo "release_name: $BSsp1b" >> $BSsp1b.seedfile
echo "source_url: $BSsp1g" >> $BSsp1b.seedfile
echo "organism_biocview: $BSsp1h" >> $BSsp1b.seedfile
echo "BSgenomeObjname: $BSsp1a" >> $BSsp1b.seedfile
echo "seqnames: $BSsp1i" >> $BSsp1b.seedfile
echo "seqs_srcdir: $BSsp1j" >> $BSsp1b.seedfile
echo '#BiocManager::install("BSgenome")' > ${BSsp1a}_forgeBSgenome.R
echo 'library("BSgenome")' >> ${BSsp1a}_forgeBSgenome.R
echo 'forgeBSgenomeDataPkg("'$BSsp1b'.seedfile")' >> ${BSsp1a}_forgeBSgenome.R

echo "Package: BSgenome.$BSsp2a.$BSsp2e.$BSsp2b" > $BSsp2b.seedfile
echo "Title: Full genome sequences for $BSsp2c (version $BSsp2b)" >> $BSsp2b.seedfile
echo "Description: Full genome sequences for $BSsp2c as provided by $BSsp2e ($BSsp2b, $BSsp2f) and stored in Biostrings objects." >> $BSsp2b.seedfile
echo "Version: $BSsp2d" >> $BSsp2b.seedfile
echo "organism: $BSsp2c" >> $BSsp2b.seedfile
echo "common_name: $BSsp2c" >> $BSsp2b.seedfile
echo "provider: $BSsp2e" >> $BSsp2b.seedfile
echo "provider_version: $BSsp2b" >> $BSsp2b.seedfile
echo "release_date: $BSsp2f" >> $BSsp2b.seedfile
echo "release_name: $BSsp2b" >> $BSsp2b.seedfile
echo "source_url: $BSsp2g" >> $BSsp2b.seedfile
echo "organism_biocview: $BSsp2h" >> $BSsp2b.seedfile
echo "BSgenomeObjname: $BSsp2a" >> $BSsp2b.seedfile
echo "seqnames: $BSsp2i" >> $BSsp2b.seedfile
echo "seqs_srcdir: $BSsp2j" >> $BSsp2b.seedfile
echo '#BiocManager::install("BSgenome")' > ${BSsp2a}_forgeBSgenome.R
echo 'library("BSgenome")' >> ${BSsp2a}_forgeBSgenome.R
echo 'forgeBSgenomeDataPkg("'$BSsp2b'.seedfile")' >> ${BSsp2a}_forgeBSgenome.R

echo "Package: BSgenome.$BSsp3a.$BSsp3e.$BSsp3b" > $BSsp3b.seedfile
echo "Title: Full genome sequences for $BSsp3c (version $BSsp3b)" >> $BSsp3b.seedfile
echo "Description: Full genome sequences for $BSsp3c as provided by $BSsp3e ($BSsp3b, $BSsp3f) and stored in Biostrings objects." >> $BSsp3b.seedfile
echo "Version: $BSsp3d" >> $BSsp3b.seedfile
echo "organism: $BSsp3c" >> $BSsp3b.seedfile
echo "common_name: $BSsp3c" >> $BSsp3b.seedfile
echo "provider: $BSsp3e" >> $BSsp3b.seedfile
echo "provider_version: $BSsp3b" >> $BSsp3b.seedfile
echo "release_date: $BSsp3f" >> $BSsp3b.seedfile
echo "release_name: $BSsp3b" >> $BSsp3b.seedfile
echo "source_url: $BSsp3g" >> $BSsp3b.seedfile
echo "organism_biocview: $BSsp3h" >> $BSsp3b.seedfile
echo "BSgenomeObjname: $BSsp3a" >> $BSsp3b.seedfile
echo "seqnames: $BSsp3i" >> $BSsp3b.seedfile
echo "seqs_srcdir: $BSsp3j" >> $BSsp3b.seedfile
echo '#BiocManager::install("BSgenome")' > ${BSsp3a}_forgeBSgenome.R
echo 'library("BSgenome")' >> ${BSsp3a}_forgeBSgenome.R
echo 'forgeBSgenomeDataPkg("'$BSsp3b'.seedfile")' >> ${BSsp3a}_forgeBSgenome.R

echo "Package: BSgenome.$BSsp4a.$BSsp4e.$BSsp4b" > $BSsp4b.seedfile
echo "Title: Full genome sequences for $BSsp4c (version $BSsp4b)" >> $BSsp4b.seedfile
echo "Description: Full genome sequences for $BSsp4c as provided by $BSsp4e ($BSsp4b, $BSsp4f) and stored in Biostrings objects." >> $BSsp4b.seedfile
echo "Version: $BSsp4d" >> $BSsp4b.seedfile
echo "organism: $BSsp4c" >> $BSsp4b.seedfile
echo "common_name: $BSsp4c" >> $BSsp4b.seedfile
echo "provider: $BSsp4e" >> $BSsp4b.seedfile
echo "provider_version: $BSsp4b" >> $BSsp4b.seedfile
echo "release_date: $BSsp4f" >> $BSsp4b.seedfile
echo "release_name: $BSsp4b" >> $BSsp4b.seedfile
echo "source_url: $BSsp4g" >> $BSsp4b.seedfile
echo "organism_biocview: $BSsp4h" >> $BSsp4b.seedfile
echo "BSgenomeObjname: $BSsp4a" >> $BSsp4b.seedfile
echo "seqnames: $BSsp4i" >> $BSsp4b.seedfile
echo "seqs_srcdir: $BSsp4j" >> $BSsp4b.seedfile
echo '#BiocManager::install("BSgenome")' > ${BSsp4a}_forgeBSgenome.R
echo 'library("BSgenome")' >> ${BSsp4a}_forgeBSgenome.R
echo 'forgeBSgenomeDataPkg("'$BSsp4b'.seedfile")' >> ${BSsp4a}_forgeBSgenome.R

echo "Package: BSgenome.$BSsp5a.$BSsp5e.$BSsp5b" > $BSsp5b.seedfile
echo "Title: Full genome sequences for $BSsp5c (version $BSsp5b)" >> $BSsp5b.seedfile
echo "Description: Full genome sequences for $BSsp5c as provided by $BSsp5e ($BSsp5b, $BSsp5f) and stored in Biostrings objects." >> $BSsp5b.seedfile
echo "Version: $BSsp5d" >> $BSsp5b.seedfile
echo "organism: $BSsp5c" >> $BSsp5b.seedfile
echo "common_name: $BSsp5c" >> $BSsp5b.seedfile
echo "provider: $BSsp5e" >> $BSsp5b.seedfile
echo "provider_version: $BSsp5b" >> $BSsp5b.seedfile
echo "release_date: $BSsp5f" >> $BSsp5b.seedfile
echo "release_name: $BSsp5b" >> $BSsp5b.seedfile
echo "source_url: $BSsp5g" >> $BSsp5b.seedfile
echo "organism_biocview: $BSsp5h" >> $BSsp5b.seedfile
echo "BSgenomeObjname: $BSsp5a" >> $BSsp5b.seedfile
echo "seqnames: $BSsp5i" >> $BSsp5b.seedfile
echo "seqs_srcdir: $BSsp5j" >> $BSsp5b.seedfile
echo '#BiocManager::install("BSgenome")' > ${BSsp5a}_forgeBSgenome.R
echo 'library("BSgenome")' >> ${BSsp5a}_forgeBSgenome.R
echo 'forgeBSgenomeDataPkg("'$BSsp5b'.seedfile")' >> ${BSsp5a}_forgeBSgenome.R

echo "Package: BSgenome.$BSsp6a.$BSsp6e.$BSsp6b" > $BSsp6b.seedfile
echo "Title: Full genome sequences for $BSsp6c (version $BSsp6b)" >> $BSsp6b.seedfile
echo "Description: Full genome sequences for $BSsp6c as provided by $BSsp6e ($BSsp6b, $BSsp6f) and stored in Biostrings objects." >> $BSsp6b.seedfile
echo "Version: $BSsp6d" >> $BSsp6b.seedfile
echo "organism: $BSsp6c" >> $BSsp6b.seedfile
echo "common_name: $BSsp6c" >> $BSsp6b.seedfile
echo "provider: $BSsp6e" >> $BSsp6b.seedfile
echo "provider_version: $BSsp6b" >> $BSsp6b.seedfile
echo "release_date: $BSsp6f" >> $BSsp6b.seedfile
echo "release_name: $BSsp6b" >> $BSsp6b.seedfile
echo "source_url: $BSsp6g" >> $BSsp6b.seedfile
echo "organism_biocview: $BSsp6h" >> $BSsp6b.seedfile
echo "BSgenomeObjname: $BSsp6a" >> $BSsp6b.seedfile
echo "seqnames: $BSsp6i" >> $BSsp6b.seedfile
echo "seqs_srcdir: $BSsp6j" >> $BSsp6b.seedfile
echo '#BiocManager::install("BSgenome")' > ${BSsp6a}_forgeBSgenome.R
echo 'library("BSgenome")' >> ${BSsp6a}_forgeBSgenome.R
echo 'forgeBSgenomeDataPkg("'$BSsp6b'.seedfile")' >> ${BSsp6a}_forgeBSgenome.R

# 2aBa. Forge BS genomes
spnumber=6 # input the total number of species for ceating BS genomes
spnumberarray=$(expr $spnumber - 1)

echo "#!/bin/bash -e" >> 2aBa.forgeBSgenomes.sh
echo "#SBATCH -p tgac-medium # partition (queue)" >> 2aBa.forgeBSgenomes.sh
echo "#SBATCH -N 1 # number of nodes" >> 2aBa.forgeBSgenomes.sh
echo "#SBATCH -n 1 # number of tasks" >> 2aBa.forgeBSgenomes.sh
echo "#SBATCH --array=0-$spnumberarray" >> 2aBa.forgeBSgenomes.sh
echo "#SBATCH --mem-per-cpu 24000" >> 2aBa.forgeBSgenomes.sh
echo "#SBATCH -t 0-03:59" >> 2aBa.forgeBSgenomes.sh
echo "#SBATCH --mail-type=ALL # notifications for job done & fail" >> 2aBa.forgeBSgenomes.sh
echo "#SBATCH --mail-user=Tarang.Mehta@earlham.ac.uk # send-to address" >> 2aBa.forgeBSgenomes.sh
echo "#SBATCH -o slurm.%N.%j.out # STDOUT" >> 2aBa.forgeBSgenomes.sh
echo "#SBATCH -e slurm.%N.%j.err # STDERR" >> 2aBa.forgeBSgenomes.sh
printf '\n' >> 2aBa.forgeBSgenomes.sh
echo "source pcre2-10.23" >> 2aBa.forgeBSgenomes.sh
echo "source /ei/software/staging/CISSUPPORT-11716/stagingloader # source R-4.0.2" >> 2aBa.forgeBSgenomes.sh
printf '\n' >> 2aBa.forgeBSgenomes.sh
echo "ls -1 *_forgeBSgenome.R > bsgenomes # create a list of all bsgenomes Rscript files" >> 2aBa.forgeBSgenomes.sh
echo 'mapfile -t bsgenomes < bsgenomes # assign as elements to $bsgenomes variable' >> 2aBa.forgeBSgenomes.sh
printf '\n' >> 2aBa.forgeBSgenomes.sh
echo 'Rscript ${bsgenomes[${SLURM_ARRAY_TASK_ID}]} # this will forge the BS genome required to run ATACseqQC' >> 2aBa.forgeBSgenomes.sh

echo '# -- 1b. FRiP calculation has completed -- #'

echo '# -- 2aBa. Peak annotation has started: forging BSgenomes-- #'

JOBID5=$( sbatch -W --dependency=afterok:${JOBID4} 2aBa.forgeBSgenomes.sh | awk '{print $4}' ) # JOB5 depends on JOB4 completing successfully


# 2aBb. Build and install BS genomes

echo "$speciesBSgenome1" >> speciesBSgenomeIDs
echo "$speciesBSgenome2" >> speciesBSgenomeIDs
echo "$speciesBSgenome3" >> speciesBSgenomeIDs
echo "$speciesBSgenome4" >> speciesBSgenomeIDs
echo "$speciesBSgenome5" >> speciesBSgenomeIDs
echo "$speciesBSgenome6" >> speciesBSgenomeIDs

echo "#!/bin/bash -e" >> 2aBb.buildBSgenomes.sh
echo "#SBATCH -p tgac-medium # partition (queue)" >> 2aBb.buildBSgenomes.sh
echo "#SBATCH -N 1 # number of nodes" >> 2aBb.buildBSgenomes.sh
echo "#SBATCH -n 1 # number of tasks" >> 2aBb.buildBSgenomes.sh
echo "#SBATCH --array=0-$spnumberarray" >> 2aBb.buildBSgenomes.sh
echo "#SBATCH --mem-per-cpu 24000" >> 2aBb.buildBSgenomes.sh
echo "#SBATCH -t 0-04:59" >> 2aBb.buildBSgenomes.sh
echo "#SBATCH --mail-type=ALL # notifications for job done & fail" >> 2aBb.buildBSgenomes.sh
echo "#SBATCH --mail-user=Tarang.Mehta@earlham.ac.uk # send-to address" >> 2aBb.buildBSgenomes.sh
echo "#SBATCH -o slurm.%N.%j.out # STDOUT" >> 2aBb.buildBSgenomes.sh
echo "#SBATCH -e slurm.%N.%j.err # STDERR" >> 2aBb.buildBSgenomes.sh
printf '\n' >> 2aBb.buildBSgenomes.sh
echo "source pcre2-10.23" >> 2aBb.buildBSgenomes.sh
echo "source /ei/software/staging/CISSUPPORT-11716/stagingloader # source R-4.0.2" >> 2aBb.buildBSgenomes.sh
printf '\n' >> 2aBb.buildBSgenomes.sh
echo 'mapfile -t bsgenomesIDs < speciesBSgenomeIDs' >> 2aBb.buildBSgenomes.sh
printf '\n' >> 2aBb.buildBSgenomes.sh
echo 'R CMD build ${bsgenomesIDs[${SLURM_ARRAY_TASK_ID}]} # this will build the BSgenome' >> 2aBb.buildBSgenomes.sh
echo 'R CMD check ${bsgenomesIDs[${SLURM_ARRAY_TASK_ID}]} # this will check the package' >> 2aBb.buildBSgenomes.sh
echo 'R CMD INSTALL ${bsgenomesIDs[${SLURM_ARRAY_TASK_ID}]} # this will install the package for loading' >> 2aBb.buildBSgenomes.sh


echo '# -- 2aBa. Peak annotation has started: forging BSgenomes has completed -- #'

echo '# -- 2aBb. Peak annotation has started: building BSgenomes -- #'

JOBID6=$( sbatch -W --dependency=afterok:${JOBID5} 2aBb.buildBSgenomes.sh | awk '{print $4}' ) # JOB5 depends on JOB4 completing successfully

# 2aBc. Run ATACseqQC: create diagnostic plots of TSS enrichment

# TO DO: CREATE A WHILE LOOP TO RUN FOR EACH SAMPLE AND IT'S GENOME -
# You need to maintain job dependencies so:
  # THROW THIS AS AN ECHO INTO A SEPARATE SBATCH SCRIPT with a long time

# mkdir -p $annotdir/Ab5_L
# Input (-i) will be nodup_filt_bam_index_file=$(echo $bam_file | sed -e 's/.bam/.nodup.filt.bam.bai/' | sed -e 's/3.Mtfilt_fragcnt/4.postalign_filt/g') # index file
# Rscript $atacqcscript -i Ab5_L_ATAC.nochrM.nodup.filt.sorted.JH425323.1.bam -g $annotAbg -s $annotdir/Ab5_L -p Ab5_L_1-PTscore.tiff -n Ab5_L_2-NFRscore.tiff -b BSgenome.Abur.Ensembl.AstBur1.0 -t Ab5_L_3-TSSscore.txt -c Ab5_L_4-cumulativepercscore.tiff -h Ab5_L_5-logtransformedTSSsignalheatmap.tiff -r Ab5_L_6-rescaledTSSsignal.tiff

echo "#!/bin/bash -e" >> $atacqcscript2
echo "#SBATCH -p tgac-medium # partition (queue)" >> $atacqcscript2
echo "#SBATCH -N 1 # number of nodes" >> $atacqcscript2
echo "#SBATCH -n 1 # number of tasks" >> $atacqcscript2
echo "#SBATCH --mem-per-cpu 60000" >> $atacqcscript2
echo "#SBATCH -t 1-23:59" >> $atacqcscript2
echo "#SBATCH --mail-type=ALL # notifications for job done & fail" >> $atacqcscript2
echo "#SBATCH --mail-user=Tarang.Mehta@earlham.ac.uk # send-to address" >> $atacqcscript2
echo "#SBATCH -o slurm.%N.%j.out # STDOUT" >> $atacqcscript2
echo "#SBATCH -e slurm.%N.%j.err # STDERR" >> $atacqcscript2
printf '\n' >> $atacqcscript2
echo -e 'while read -r i1 i2; do' >> $atacqcscript2
echo -e '\tif [[ "$i1" == "'$speciesid1'" ]]; then' >> $atacqcscript2
echo -e '\t\tmkdir '$annotdir'/$i2' >> $atacqcscript2
echo -e '\t\tcd '$WD'/$i2' >> $atacqcscript2
echo -e '\t\tRscript '$atacqcscript' -i '$scripts'/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g '$annotMzg' -s '$annotdir'/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b '$speciesBSgenome1' -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff' >> $atacqcscript2
echo -e '\tfi' >> $atacqcscript2
echo -e '\tif [[ "$i1" == "'$speciesid2'" ]]; then' >> $atacqcscript2
echo -e '\t\tmkdir '$annotdir'/$i2' >> $atacqcscript2
echo -e '\t\tcd '$WD'/$i2' >> $atacqcscript2
echo -e '\t\tRscript '$atacqcscript' -i '$scripts'/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g '$annotPng' -s '$annotdir'/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b '$speciesBSgenome2' -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff' >> $atacqcscript2
echo -e '\tfi' >> $atacqcscript2
echo -e '\tif [[ "$i1" == "'$speciesid3'" ]]; then' >> $atacqcscript2
echo -e '\t\tmkdir '$annotdir'/$i2' >> $atacqcscript2
echo -e '\t\tcd '$WD'/$i2' >> $atacqcscript2
echo -e '\t\tRscript '$atacqcscript' -i '$scripts'/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g '$annotAbg' -s '$annotdir'/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b '$speciesBSgenome3' -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff' >> $atacqcscript2
echo -e '\tfi' >> $atacqcscript2
echo -e '\tif [[ "$i1" == "'$speciesid4'" ]]; then' >> $atacqcscript2
echo -e '\t\tmkdir '$annotdir'/$i2' >> $atacqcscript2
echo -e '\t\tcd '$WD'/$i2' >> $atacqcscript2
echo -e '\t\tRscript '$atacqcscript' -i '$scripts'/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g '$annotNbg' -s '$annotdir'/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b '$speciesBSgenome4' -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff' >> $atacqcscript2
echo -e '\tfi' >> $atacqcscript2
echo -e '\tfi' >> $atacqcscript2
echo -e '\tif [[ "$i1" == "'$speciesid5'" ]]; then' >> $atacqcscript2
echo -e '\t\tmkdir '$annotdir'/$i2' >> $atacqcscript2
echo -e '\t\tcd '$WD'/$i2' >> $atacqcscript2
echo -e '\t\tRscript '$atacqcscript' -i '$scripts'/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g '$annotOng' -s '$annotdir'/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b '$speciesBSgenome5' -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff' >> $atacqcscript2
echo -e '\tfi' >> $atacqcscript2
echo -e '\tfi' >> $atacqcscript2
echo -e '\tif [[ "$i1" == "'$speciesid6'" ]]; then' >> $atacqcscript2
echo -e '\t\tmkdir '$annotdir'/$i2' >> $atacqcscript2
echo -e '\t\tcd '$WD'/$i2' >> $atacqcscript2
echo -e '\t\tRscript '$atacqcscript' -i '$scripts'/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g '$annotAcg' -s '$annotdir'/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b '$speciesBSgenome6' -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff' >> $atacqcscript2
echo -e '\tfi' >> $atacqcscript2
"done < $prefixATAC2" # this while loop will run ATAC script in each ATAC folder




# while read -r i1 i2; do
#   if [[ "$i1" == "$speciesid1" ]]; then
#     mkdir $annotdir/$i2
#     cd $WD/$i2
#     Rscript $atacqcscript -i $scripts/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g $annotMzg -s $annotdir/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b $speciesBSgenome1 -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff
#   fi
#   if [[ "$i1" == "$speciesid2" ]]; then
#     mkdir $annotdir/$i2
#     cd $WD/$i2
#     Rscript $atacqcscript -i $scripts/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g $annotPng -s $annotdir/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b $speciesBSgenome2 -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff
#   fi
#   if [[ "$i1" == "$speciesid3" ]]; then
#     mkdir $annotdir/$i2
#     cd $WD/$i2
#     Rscript $atacqcscript -i $scripts/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g $annotAbg -s $annotdir/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b $speciesBSgenome3 -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff
#   fi
#   if [[ "$i1" == "$speciesid4" ]]; then
#     mkdir $annotdir/$i2
#     cd $WD/$i2
#     Rscript $atacqcscript -i $scripts/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g $annotNbg -s $annotdir/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b $speciesBSgenome4 -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff
#   fi
#   if [[ "$i1" == "$speciesid5" ]]; then
#     mkdir $annotdir/$i2
#     cd $WD/$i2
#     Rscript $atacqcscript -i $scripts/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g $annotOng -s $annotdir/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b $speciesBSgenome5 -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff
#   fi
#   if [[ "$i1" == "$speciesid6" ]]; then
#     mkdir $annotdir/$i2
#     cd $WD/$i2
#     Rscript $atacqcscript -i $scripts/${i2}/4.postalign_filt/${i2}.nochrM.nodup.filt.sorted.bam -g $annotAcg -s $annotdir/${i2} -p ${i2}_1-PTscore.tiff -n ${i2}_2-NFRscore.tiff -b $speciesBSgenome6 -t ${i2}_3-TSSscore.txt -c ${i2}_4-cumulativepercscore.tiff -h ${i2}_5-logtransformedTSSsignalheatmap.tiff -r ${i2}_6-rescaledTSSsignal.tiff
#   fi
# done < $prefixATAC2 # this while loop will run ATAC script in each ATAC folder

echo '# -- 2aBb. Peak annotation has started: building BSgenomes has completed -- #'

echo '# -- 2aBc. Peak annotation has started: running ATACseqQC -- #'

JOBID7=$( sbatch -W --dependency=afterok:${JOBID6} XX | awk '{print $4}' ) # JOB7 depends on JOB6 completing successfully


# make_option(c("-i", "--input"), action="store", default=NA, type='character',
#             help="input *.bam file (nochrM-nodup-filtered-sorted; non-shifted!!)"),
# make_option(c("-g", "--gtf"), action="store", default=NA, type='character',
#             help="input *.gtf file"),
# make_option(c("-s", "--shiftbam"), action="store", default=NA, type='character',
#             help="path to output shifted and split BAMs - make and name path folder according to sample and tissue"),
# make_option(c("-p", "--ptp"), action="store", default=NA, type='character',
#             help="output *.tiff filename for Promoter-Transcript score plot"),
# make_option(c("-n", "--nfrp"), action="store", default=NA, type='character',
#             help="output *.tiff filename for NFR score plot"),
# make_option(c("-b", "--bsgenome"), action="store", default=NA, type='character',
#             help="BSgenome package dir as built in shell script e.g. BSgenome.Abur.Ensembl.AstBur1.0"),
# make_option(c("-t", "--tssscore"), action="store", default=NA, type='character',
#             help="output *.txt filename for TSS enrichment score summary"),
# make_option(c("-c", "--cpp"), action="store", default=NA, type='character',
#             help="output *.tiff filename for cumulative percentage plot"),
# make_option(c("-h", "--hmp"), action="store", default=NA, type='character',
#             help="output *.tiff filename for log-transformed signal around TSSs"),
# make_option(c("-r", "--rsp"), action="store", default=NA, type='character',
#             help="output *.tiff filename for rescaled signal around TSSs")

# NEED TO ADD FRACTION OF READS IN ANNOTATE REGIONS SCRIPT Here

echo '# -- 2b. Fraction of Reads in annotated regions has started -- #'


################################################################################################################

### 3. TF footprinting and creation of signal tracks

######### TO DO
# 0. Add A. calliptera using M. zebra motifs - add variables of A. calliptera at top if required
# 1. IN POINT 2 USING ATACSEQQC, CREATE A SHIFTED BAM (this has been input as -s option > output is $annotdir/Ab5_L.shifted.bam) AND USE THIS FOR FOOTPRINTING!!!!
# 2. CHANGE ALL PATHS TO THE NEW BAM TO USE BELOW IN THIS SECTION!!
# 3. Ensure all echo of started, completed and job numbers are ok

# Signal tracks are generated from BAM file (Raw) and bias corrected by HINT-ATAC
# This is rolled in with TF footprinting using HINT-ATAC, see this: https://www.regulatory-genomics.org/hint/tutorial/

# HINT-ATAC installed by installing RGT - Regulatory Genomics Toolbox: https://github.com/CostaLab/reg-gen
# install locally as config files need amending and other files need adding to the installation directory
# source ~/.bash_profile
# source ~/.bashrc
# ml gcc
# ml zlib
# pip install --user cython numpy scipy
# pip install --user RGT --no-binary RGT
# conda install -c bioconda pybigwig
## Local installations of RGT are here:
# /hpc-home/mehtat/.local/bin/bedGraphToBigWig
# /hpc-home/mehtat/.local/bin/bedToBigBed
# /hpc-home/mehtat/.local/bin/bigBedToBed
# /hpc-home/mehtat/.local/bin/bigWigMerge
# /hpc-home/mehtat/.local/bin/rgt-TDF
# /hpc-home/mehtat/.local/bin/rgt-THOR
# /hpc-home/mehtat/.local/bin/rgt-filterVCF
# /hpc-home/mehtat/.local/bin/rgt-hint
# /hpc-home/mehtat/.local/bin/rgt-motifanalysis
# /hpc-home/mehtat/.local/bin/rgt-viz
# /hpc-home/mehtat/.local/bin/wigToBigWig
# /hpc-home/mehtat/.local/lib/python3.7/site-packages/RGT-0.13.0-py3.7.egg-info
# /hpc-home/mehtat/.local/lib/python3.7/site-packages/rgt

# 1. Customise RGT data folder and data.config.user file for own genome files etc.: http://www.regulatory-genomics.org/rgt/rgt-data-folder/

# mkdir -p $tffprdir
cd $tffprdir

# A. For each genome, the following is required:
# Aa. chromosome size files
source bioawk-1.0
while read -r a; do
  bioawk -c fastx '{ print $name, length($seq) }' < ${a} | awk '{print $1,$2}' OFS="\t" > $(echo "${a}" | sed 's/.fa/.fa.chrom.sizes/g')
done < $genfastas

# bioawk -c fastx '{ print $name, length($seq) }' < $AbgFA | awk '{print $1,$2}' OFS="\t" > $Abgchr
# bioawk -c fastx '{ print $name, length($seq) }' < $MzgFA | awk '{print $1,$2}' OFS="\t" > $Mzgchr
# bioawk -c fastx '{ print $name, length($seq) }' < $PngFA | awk '{print $1,$2}' OFS="\t" > $Pngchr
# bioawk -c fastx '{ print $name, length($seq) }' < $NbgFA | awk '{print $1,$2}' OFS="\t" > $Nbgchr
# bioawk -c fastx '{ print $name, length($seq) }' < $OngFA | awk '{print $1,$2}' OFS="\t" > $Ongchr

# Ab. Two gene regions file in bed format
## 1. For the genes_Gencode file use ensemblIDS
while read -r b; do
  cat ${b} | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$10,".",$7}}' | tr -d '";' > $(echo "${b}" | sed 's/100.gtf/100.generegions_Gencode.bed/g')
done < $antfiles

# cat $annotAbg | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$10,".",$7}}' | tr -d '";' > $AbggenGC
# cat $annotMzg | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$10,".",$7}}' | tr -d '";' > $MzggenGC
# cat $annotPng | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$10,".",$7}}' | tr -d '";' > $PnggenGC
# cat $annotNbg | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$10,".",$7}}' | tr -d '";' > $NbggenGC
# cat $annotOng | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$10,".",$7}}' | tr -d '";' > $OnggenGC

## 2. For the genes_RefSeq file use gene symbol
while read -r b; do
  cat ${b} | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$14,".",$7}}' | tr -d '";' | sed 's/ensembl/NA/g' > $(echo "${b}" | sed 's/100.gtf/100.generegions_RefSeq.bed/g')
done < $antfiles

# cat $annotAbg | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$14,".",$7}}' | tr -d '";' | sed 's/ensembl/NA/g' > $AbggenRS
# cat $annotMzg | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$14,".",$7}}' | tr -d '";' | sed 's/ensembl/NA/g' > $MzggenRS
# cat $annotPng | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$14,".",$7}}' | tr -d '";' | sed 's/ensembl/NA/g' > $PnggenRS
# cat $annotNbg | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$14,".",$7}}' | tr -d '";' | sed 's/ensembl/NA/g' > $NbggenRS
# cat $annotOng | awk 'OFS="\t" {if ($3=="gene") {print $1,$4-1,$5,$14,".",$7}}' | tr -d '";' | sed 's/ensembl/NA/g' > $OnggenRS

# Ac. gene alias file in text format - prepare from the gtf and BioMart

# Ac-1. awk from gtf to create a 2 colum file; col1=ensemblID, col2=gene_symbol (NA if 'ensembl' as symbol)- $file1
printf 'ensembl_gene_id\tensembl_gene_symbol\n' > tmpgenealias_header.txt
while read -r c; do
# for i in "$Mzgannot" "$Pngannot" "$Abgannot" "$Nbgannot" "$Ongannot"; do
  cat ${c} | awk 'OFS="\t" {if ($3=="gene") {print $0}}' |
  awk '{print $10,$14}' OFS='\t' |
  sed 's/"//g' | sed 's/;//g' |
  awk '{$2=tolower($2);print}' OFS='\t' |
  sed 's/ensembl/NA/g' > $(echo "${c}" | sed 's/.gtf/.genealias.txt.tmp0/g')
  cat tmpgenealias_header.txt $(echo "${c}" | sed 's/.gtf/.genealias.txt.tmp0/g') > $(echo "${c}" | sed 's/.gtf/.genealias.txt.tmp1/g')
  rm $(echo "${c}" | sed 's/.gtf/.genealias.txt.tmp0/g')
done < $antfiles

# Ac-2. Download the following for each genome from BIOMART (below are the col headers)
  # ensembl_gene_id
  # ensembl_gene_id_version
  # ensembl_transcript_id
  # ensembl_transcript_id_version
  # hgnc_id
  # hgnc_symbol
  # entrezgene_accession
  # refseq_mrna_predicted
  # uniprotswissprot
  # wikigene_name
  # zfin_id_id
  # wikigene_id

# *- Go to here: https://m.ensembl.org/biomart/martview/246998056a05b7c965d983144dd0ddf6
# *-- Select 'Database' of genes and 'Attributes'
# *--- Once selected, click xml, copy and paste onto one line after wget -O result.txt 'http://www.ensembl.org/biomart/martservice?query=[INSERT XML HERE ON ONE LINE]'
# *---- Saved file will be stored as 'result.txt' so rename
# *----- Simply change the genome in '<Dataset name = "hburtoni_gene_ensembl"' to download other sets
  # mzebra_gene_ensembl
  # pnyererei_gene_ensembl
  # hburtoni_gene_ensembl
  # nbrichardi_gene_ensembl - not available
  # oniloticus_gene_ensembl

echo '#!/bin/bash -e' > 2.2_biomart_dl.sh
echo '#SBATCH -p tgac-short # partition (queue)' >> 2.2_biomart_dl.sh
echo '#SBATCH -N 1 # number of nodes' >> 2.2_biomart_dl.sh
echo '#SBATCH -c 1 # number of cores' >> 2.2_biomart_dl.sh
echo '#SBATCH --mem 8000 # memory pool for all cores' >> 2.2_biomart_dl.sh
echo '#SBATCH -t 0-00:45 # time (D-HH:MM)' >> 2.2_biomart_dl.sh
echo '#SBATCH -o slurm.%j.out # STDOUT' >> 2.2_biomart_dl.sh
echo '#SBATCH -e slurm.%j.err # STDERR' >> 2.2_biomart_dl.sh
echo '#SBATCH --mail-type=END,FAIL,TIME_LIMIT_75 # notifications for job done & fail' >> 2.2_biomart_dl.sh
echo '#SBATCH --mail-user=Tarang.Mehta@earlham.ac.uk # send-to addressUSERNAME=mehtat' >> 2.2_biomart_dl.sh
printf '\n' >> 2.2_biomart_dl.sh
echo "# this script will access the software node to download the biomart dbs" >> 2.2_biomart_dl.sh
echo 'source wget-1.14' >> 2.2_biomart_dl.sh
echo "USERNAME=$Usr" >> 2.2_biomart_dl.sh
echo 'HOSTNAME="software"' >> 2.2_biomart_dl.sh
echo "PWD=$(pwd)" >> 2.2_biomart_dl.sh
printf '\n' >> 2.2_biomart_dl.sh
echo 'SCRIPT="cd ${PWD}; sh 2.2_biomart_dl_script.sh"' >> 2.2_biomart_dl.sh
printf '\n' >> 2.2_biomart_dl.sh
echo "cd ${PWD}" > 2.2_biomart_dl_script.sh
echo "while read -r i; do" >> 2.2_biomart_dl_script.sh
echo -e '\twget -O ${i}_biomart1.txt '"'"'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "'"'"'${i}'"'"'" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "ensembl_gene_id_version" /><Attribute name = "ensembl_transcript_id" /><Attribute name = "ensembl_transcript_id_version" /><Attribute name = "hgnc_id" /></Dataset></Query>'"'" >> 2.2_biomart_dl_script.sh
echo -e '\twget -O ${i}_biomart2.txt '"'"'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "'"'"'${i}'"'"'" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "hgnc_symbol" /><Attribute name = "entrezgene_accession" /><Attribute name = "refseq_mrna_predicted" /></Dataset></Query>'"'" >> 2.2_biomart_dl_script.sh
echo -e '\twget -O ${i}_biomart3.txt '"'"'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "'"'"'${i}'"'"'" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "uniprotswissprot" /><Attribute name = "wikigene_name" /></Dataset></Query>'"'" >> 2.2_biomart_dl_script.sh
echo -e '\twget -O ${i}_biomart4.txt '"'"'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "'"'"'${i}'"'"'" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "zfin_id_id" /><Attribute name = "wikigene_id" /></Dataset></Query>'"'" >> 2.2_biomart_dl_script.sh
echo "done < $biomartspecies" >> 2.2_biomart_dl_script.sh
echo 'exit' >> 2.2_biomart_dl_script.sh
echo 'ssh -o StrictHostKeyChecking=no -l ${USERNAME} ${HOSTNAME} "${SCRIPT}"' >> 2.2_biomart_dl.sh
printf '\n' >> 2.2_biomart_dl.sh
echo "printf 'ensembl_transcript_id\thgnc_symbol\tentrezgene_accession\trefseq_mrna_predicted\tensembl_gene_id\tensembl_gene_id_version\tensembl_transcript_id\tensembl_transcript_id_version\thgnc_id\tensembl_transcript_id\tuniprotswissprot\twikigene_name\tensembl_transcript_id\tzfin_id_id\twikigene_id\n' > "'biomart_headers # NOTE - many of these cols will get removed later' >> 2.2_biomart_dl.sh
echo "while read -r i; do" >> 2.2_biomart_dl.sh
echo -e "\tawk '"'!$5{print $0,"NA";next}1'"' "'${i}_biomart1.txt > ${i}_biomart1a.txt # fill the 5th column with NA if empty' >> 2.2_biomart_dl.sh
echo -e "\tawk '"'!$2{print $0,"NA";next}1'"' "'${i}_biomart2.txt | awk '"'"'!$3{print $0,"NA";next}1'"' | awk '"'!$4{print $0,"NA";next}1'"' > "'${i}_biomart2a.txt # fill the 2nd, 3rd and 4th column with NA if empty' >> 2.2_biomart_dl.sh
echo -e "\tawk '"'!$2{print $0,"NA";next}1'"' "'${i}_biomart3.txt | awk '"'"'!$3{print $0,"NA";next}1'"' > "'${i}_biomart3a.txt # fill the 2nd and 3rd column with NA if empty' >> 2.2_biomart_dl.sh
echo -e "\tawk '"'!$2{print $0,"NA";next}1'"' "'${i}_biomart4.txt | awk '"'"'!$3{print $0,"NA";next}1'"' > "'${i}_biomart4a.txt # fill the 2nd and 3rd column with NA if empty' >> 2.2_biomart_dl.sh
echo -e '\tawk '"'BEGIN{OFS="'"\t"}NR==FNR{a[$3]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA";}}'"' "'${i}_biomart1a.txt ${i}_biomart2a.txt > ${i}_biomart1-2a.txt' >> 2.2_biomart_dl.sh
echo -e '\tawk '"'BEGIN{OFS="'"\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}'"' "'${i}_biomart3a.txt ${i}_biomart1-2a.txt > ${i}_biomart1-2-3a.txt' >> 2.2_biomart_dl.sh
echo -e '\tawk '"'BEGIN{OFS="'"\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}'"' "'${i}_biomart4a.txt ${i}_biomart1-2-3a.txt > ${i}_biomart.tmp.txt' >> 2.2_biomart_dl.sh
echo -e '\tcat biomart_headers ${i}_biomart.tmp.txt | awk '"'{print "'$1,$2,$3,$4,$5,$6,$8,$9,$11,$12,$14,$15}'"' OFS='\t' | awk '{print "'$5,$6,$1,$7,$8,$2,$3,$4,$9,$10,$11,$12}'"' OFS='\t' > "'${i}_biomart.txt' >> 2.2_biomart_dl.sh
echo -e '\trm ${i}_biomart.tmp.txt' >> 2.2_biomart_dl.sh
echo "done < $biomartspecies" >> 2.2_biomart_dl.sh

echo '# -- 2a. Peak annotation has completed -- #'

echo '# -- 2b. Fraction of Reads in annotated regions has completed -- #'

echo '# -- 3a. TF footprinting preparation has started - bioMart alias, annotations and data.config prep -- #'

JOBID6=$( sbatch -W --dependency=afterok:${JOBID5} 2.2_biomart_dl.sh | awk '{print $4}' ) # JOB6 depends on JOB5 completing successfully


# # while loop original placed in script above, and a while loop version of the longer version below
# while read -r i; do
#   wget -O ${i}_biomart1.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "'${i}'" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "ensembl_gene_id_version" /><Attribute name = "ensembl_transcript_id" /><Attribute name = "ensembl_transcript_id_version" /><Attribute name = "hgnc_id" /></Dataset></Query>'
#   awk '!$5{print $0,"NA";next}1' ${i}_biomart1.txt > ${i}_biomart1a.txt # fill the 5th column with NA if empty
#   wget -O ${i}_biomart2.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "'${i}'" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "hgnc_symbol" /><Attribute name = "entrezgene_accession" /><Attribute name = "refseq_mrna_predicted" /></Dataset></Query>'
#   awk '!$2{print $0,"NA";next}1' ${i}_biomart2.txt | awk '!$3{print $0,"NA";next}1' | awk '!$4{print $0,"NA";next}1' > ${i}_biomart2a.txt # fill the 2nd, 3rd and 4th column with NA if empty
#   wget -O ${i}_biomart3.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "'${i}'" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "uniprotswissprot" /><Attribute name = "wikigene_name" /></Dataset></Query>'
#   awk '!$2{print $0,"NA";next}1' ${i}_biomart3.txt | awk '!$3{print $0,"NA";next}1' > ${i}_biomart3a.txt # fill the 2nd and 3rd column with NA if empty
#   wget -O ${i}_biomart4.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "'${i}'" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "zfin_id_id" /><Attribute name = "wikigene_id" /></Dataset></Query>'
#   awk '!$2{print $0,"NA";next}1' ${i}_biomart4.txt | awk '!$3{print $0,"NA";next}1' > ${i}_biomart4a.txt # fill the 2nd and 3rd column with NA if empty
#   awk 'BEGIN{OFS="\t"}NR==FNR{a[$3]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA";}}' ${i}_biomart1a.txt ${i}_biomart2a.txt > ${i}_biomart1-2a.txt
#   awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}' ${i}_biomart3a.txt ${i}_biomart1-2a.txt > ${i}_biomart1-2-3a.txt
#   awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}' ${i}_biomart4a.txt ${i}_biomart1-2-3a.txt > ${i}_biomart.tmp.txt
#   printf 'ensembl_transcript_id\thgnc_symbol\tentrezgene_accession\trefseq_mrna_predicted\tensembl_gene_id\tensembl_gene_id_version\tensembl_transcript_id\tensembl_transcript_id_version\thgnc_id\tensembl_transcript_id\tuniprotswissprot\twikigene_name\tensembl_transcript_id\tzfin_id_id\twikigene_id\n' > biomart_headers # NOTE - many of these cols will get removed later
#   cat biomart_headers ${i}_biomart.tmp.txt | awk '{print $1,$2,$3,$4,$5,$6,$8,$9,$11,$12,$14,$15}' OFS='\t' | awk '{print $5,$6,$1,$7,$8,$2,$3,$4,$9,$10,$11,$12}' OFS='\t' > ${i}_biomart.txt
#   rm ${i}_biomart.tmp.txt
# done < $biomartspecies

# # Zebra mbuna genes (M_zebra_UMD2a)
# # wget -O mz_biomart.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "mzebra_gene_ensembl" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "ensembl_gene_id_version" /><Attribute name = "ensembl_transcript_id" /><Attribute name = "ensembl_transcript_id_version" /><Attribute name = "hgnc_id" /><Attribute name = "hgnc_symbol" /><Attribute name = "entrezgene_accession" /><Attribute name = "refseq_mrna_predicted" /><Attribute name = "uniprotswissprot" /><Attribute name = "wikigene_name" /><Attribute name = "zfin_id_id" /><Attribute name = "wikigene_id" /></Dataset></Query>' # this will not work as biomart cannot process this many attributes
#
# wget -O mz_biomart1.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "mzebra_gene_ensembl" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "ensembl_gene_id_version" /><Attribute name = "ensembl_transcript_id" /><Attribute name = "ensembl_transcript_id_version" /><Attribute name = "hgnc_id" /></Dataset></Query>'
# awk '!$5{print $0,"NA";next}1' mz_biomart1.txt > mz_biomart1a.txt # fill the 5th column with NA if empty
#
# wget -O mz_biomart2.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "mzebra_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "hgnc_symbol" /><Attribute name = "entrezgene_accession" /><Attribute name = "refseq_mrna_predicted" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' mz_biomart2.txt | awk '!$3{print $0,"NA";next}1' | awk '!$4{print $0,"NA";next}1' > mz_biomart2a.txt # fill the 2nd, 3rd and 4th column with NA if empty
#
# wget -O mz_biomart3.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "mzebra_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "uniprotswissprot" /><Attribute name = "wikigene_name" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' mz_biomart3.txt | awk '!$3{print $0,"NA";next}1' > mz_biomart3a.txt # fill the 2nd and 3rd column with NA if empty
#
# wget -O mz_biomart4.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "mzebra_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "zfin_id_id" /><Attribute name = "wikigene_id" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' mz_biomart4.txt | awk '!$3{print $0,"NA";next}1' > mz_biomart4a.txt # fill the 2nd and 3rd column with NA if empty
#
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$3]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA";}}' mz_biomart1a.txt mz_biomart2a.txt > mz_biomart1-2a.txt
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}' mz_biomart3a.txt mz_biomart1-2a.txt > mz_biomart1-2-3a.txt
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}' mz_biomart4a.txt mz_biomart1-2-3a.txt > mz_biomart.tmp.txt
#
# printf 'ensembl_transcript_id\thgnc_symbol\tentrezgene_accession\trefseq_mrna_predicted\tensembl_gene_id\tensembl_gene_id_version\tensembl_transcript_id\tensembl_transcript_id_version\thgnc_id\tensembl_transcript_id\tuniprotswissprot\twikigene_name\tensembl_transcript_id\tzfin_id_id\twikigene_id\n' > biomart_headers # NOTE - many of these cols will get removed later
# # printf 'ensembl_gene_id\tensembl_gene_id_version\tensembl_transcript_id\tensembl_transcript_id_version\thgnc_id\tensembl_transcript_id\thgnc_symbol\tentrezgene_accession\trefseq_mrna_predicted\tensembl_transcript_id\tuniprotswissprot\twikigene_name\tensembl_transcript_id\tzfin_id_id\twikigene_id\n' > biomart_headers
# cat biomart_headers mz_biomart.tmp.txt | awk '{print $1,$2,$3,$4,$5,$6,$8,$9,$11,$12,$14,$15}' OFS='\t' | awk '{print $5,$6,$1,$7,$8,$2,$3,$4,$9,$10,$11,$12}' OFS='\t' > mz_biomart.txt
#
#
# # Makobe Island cichlid genes (PunNye1.0)
# # wget -O pn_biomart.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "pnyererei_gene_ensembl" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "ensembl_gene_id_version" /><Attribute name = "ensembl_transcript_id" /><Attribute name = "ensembl_transcript_id_version" /><Attribute name = "hgnc_id" /><Attribute name = "hgnc_symbol" /><Attribute name = "entrezgene_accession" /><Attribute name = "refseq_mrna_predicted" /><Attribute name = "uniprotswissprot" /><Attribute name = "wikigene_name" /><Attribute name = "zfin_id_id" /><Attribute name = "wikigene_id" /></Dataset></Query>' # this will not work as biomart cannot process this many attributes
#
# wget -O pn_biomart1.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "pnyererei_gene_ensembl" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "ensembl_gene_id_version" /><Attribute name = "ensembl_transcript_id" /><Attribute name = "ensembl_transcript_id_version" /><Attribute name = "hgnc_id" /></Dataset></Query>'
# awk '!$5{print $0,"NA";next}1' pn_biomart1.txt > pn_biomart1a.txt # fill the 5th column with NA if empty
#
# wget -O pn_biomart2.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "pnyererei_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "hgnc_symbol" /><Attribute name = "entrezgene_accession" /><Attribute name = "refseq_mrna_predicted" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' pn_biomart2.txt | awk '!$3{print $0,"NA";next}1' | awk '!$4{print $0,"NA";next}1' > pn_biomart2a.txt # fill the 2nd, 3rd and 4th column with NA if empty
#
# wget -O pn_biomart3.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "pnyererei_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "uniprotswissprot" /><Attribute name = "wikigene_name" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' pn_biomart3.txt | awk '!$3{print $0,"NA";next}1' > pn_biomart3a.txt # fill the 2nd and 3rd column with NA if empty
#
# wget -O pn_biomart4.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "pnyererei_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "zfin_id_id" /><Attribute name = "wikigene_id" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' pn_biomart4.txt | awk '!$3{print $0,"NA";next}1' > pn_biomart4a.txt # fill the 2nd and 3rd column with NA if empty
#
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$3]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA";}}' pn_biomart1a.txt pn_biomart2a.txt > pn_biomart1-2a.txt
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}' pn_biomart3a.txt pn_biomart1-2a.txt > pn_biomart1-2-3a.txt
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}' pn_biomart4a.txt pn_biomart1-2-3a.txt > pn_biomart.tmp.txt
#
# printf 'ensembl_transcript_id\thgnc_symbol\tentrezgene_accession\trefseq_mrna_predicted\tensembl_gene_id\tensembl_gene_id_version\tensembl_transcript_id\tensembl_transcript_id_version\thgnc_id\tensembl_transcript_id\tuniprotswissprot\twikigene_name\tensembl_transcript_id\tzfin_id_id\twikigene_id\n' > biomart_headers # NOTE - many of these cols will get removed later
# # printf 'ensembl_gene_id\tensembl_gene_id_version\tensembl_transcript_id\tensembl_transcript_id_version\thgnc_id\tensembl_transcript_id\thgnc_symbol\tentrezgene_accession\trefseq_mrna_predicted\tensembl_transcript_id\tuniprotswissprot\twikigene_name\tensembl_transcript_id\tzfin_id_id\twikigene_id\n' > biomart_headers
# cat biomart_headers pn_biomart.tmp.txt | awk '{print $1,$2,$3,$4,$5,$6,$8,$9,$11,$12,$14,$15}' OFS='\t' | awk '{print $5,$6,$1,$7,$8,$2,$3,$4,$9,$10,$11,$12}' OFS='\t' > pn_biomart.txt
#
#
# # Burton's mouthbrooder genes (AstBur1.0)
# # wget -O ab_biomart.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "hburtoni_gene_ensembl" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "ensembl_gene_id_version" /><Attribute name = "ensembl_transcript_id" /><Attribute name = "ensembl_transcript_id_version" /><Attribute name = "hgnc_id" /><Attribute name = "hgnc_symbol" /><Attribute name = "entrezgene_accession" /><Attribute name = "refseq_mrna_predicted" /><Attribute name = "uniprotswissprot" /><Attribute name = "wikigene_name" /><Attribute name = "zfin_id_id" /><Attribute name = "wikigene_id" /></Dataset></Query>' # this will not work as biomart cannot process this many attributes
#
# wget -O ab_biomart1.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "hburtoni_gene_ensembl" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "ensembl_gene_id_version" /><Attribute name = "ensembl_transcript_id" /><Attribute name = "ensembl_transcript_id_version" /><Attribute name = "hgnc_id" /></Dataset></Query>'
# awk '!$5{print $0,"NA";next}1' ab_biomart1.txt > ab_biomart1a.txt # fill the 5th column with NA if empty
#
# wget -O ab_biomart2.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "hburtoni_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "hgnc_symbol" /><Attribute name = "entrezgene_accession" /><Attribute name = "refseq_mrna_predicted" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' ab_biomart2.txt | awk '!$3{print $0,"NA";next}1' | awk '!$4{print $0,"NA";next}1' > ab_biomart2a.txt # fill the 2nd, 3rd and 4th column with NA if empty
#
# wget -O ab_biomart3.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "hburtoni_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "uniprotswissprot" /><Attribute name = "wikigene_name" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' ab_biomart3.txt | awk '!$3{print $0,"NA";next}1' > ab_biomart3a.txt # fill the 2nd and 3rd column with NA if empty
#
# wget -O ab_biomart4.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "hburtoni_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "zfin_id_id" /><Attribute name = "wikigene_id" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' ab_biomart4.txt | awk '!$3{print $0,"NA";next}1' > ab_biomart4a.txt # fill the 2nd and 3rd column with NA if empty
#
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$3]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA";}}' ab_biomart1a.txt ab_biomart2a.txt > ab_biomart1-2a.txt
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}' ab_biomart3a.txt ab_biomart1-2a.txt > ab_biomart1-2-3a.txt
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}' ab_biomart4a.txt ab_biomart1-2-3a.txt > ab_biomart.tmp.txt
#
# printf 'ensembl_transcript_id\thgnc_symbol\tentrezgene_accession\trefseq_mrna_predicted\tensembl_gene_id\tensembl_gene_id_version\tensembl_transcript_id\tensembl_transcript_id_version\thgnc_id\tensembl_transcript_id\tuniprotswissprot\twikigene_name\tensembl_transcript_id\tzfin_id_id\twikigene_id\n' > biomart_headers # NOTE - many of these cols will get removed later
# # printf 'ensembl_gene_id\tensembl_gene_id_version\tensembl_transcript_id\tensembl_transcript_id_version\thgnc_id\tensembl_transcript_id\thgnc_symbol\tentrezgene_accession\trefseq_mrna_predicted\tensembl_transcript_id\tuniprotswissprot\twikigene_name\tensembl_transcript_id\tzfin_id_id\twikigene_id\n' > biomart_headers
# cat biomart_headers ab_biomart.tmp.txt | awk '{print $1,$2,$3,$4,$5,$6,$8,$9,$11,$12,$14,$15}' OFS='\t' | awk '{print $5,$6,$1,$7,$8,$2,$3,$4,$9,$10,$11,$12}' OFS='\t' > ab_biomart.txt
#
#
# # Lyretail cichlid (NeoBri1.0) - check as this is not in BioMart online (poor annotation!)
# # Since this is not in biomart, just stick with $file1 as the gene alias file
#
# # Nile tilapia genes (O_niloticus_UMD_NMBU)
# # wget -O on_biomart.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "oniloticus_gene_ensembl" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "ensembl_gene_id_version" /><Attribute name = "ensembl_transcript_id" /><Attribute name = "ensembl_transcript_id_version" /><Attribute name = "hgnc_id" /><Attribute name = "hgnc_symbol" /><Attribute name = "entrezgene_accession" /><Attribute name = "refseq_mrna_predicted" /><Attribute name = "uniprotswissprot" /><Attribute name = "wikigene_name" /><Attribute name = "zfin_id_id" /><Attribute name = "wikigene_id" /></Dataset></Query>' # this will not work as biomart cannot process this many attributes
#
# wget -O on_biomart1.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "oniloticus_gene_ensembl" interface = "default" ><Attribute name = "ensembl_gene_id" /><Attribute name = "ensembl_gene_id_version" /><Attribute name = "ensembl_transcript_id" /><Attribute name = "ensembl_transcript_id_version" /><Attribute name = "hgnc_id" /></Dataset></Query>'
# awk '!$5{print $0,"NA";next}1' on_biomart1.txt > on_biomart1a.txt # fill the 5th column with NA if empty
#
# wget -O on_biomart2.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "oniloticus_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "hgnc_symbol" /><Attribute name = "entrezgene_accession" /><Attribute name = "refseq_mrna_predicted" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' on_biomart2.txt | awk '!$3{print $0,"NA";next}1' | awk '!$4{print $0,"NA";next}1' > on_biomart2a.txt # fill the 2nd, 3rd and 4th column with NA if empty
#
# wget -O on_biomart3.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "oniloticus_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "uniprotswissprot" /><Attribute name = "wikigene_name" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' on_biomart3.txt | awk '!$3{print $0,"NA";next}1' > on_biomart3a.txt # fill the 2nd and 3rd column with NA if empty
#
# wget -O on_biomart4.txt 'http://www.ensembl.org/biomart/martservice?query=<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE Query><Query  virtualSchemaName = "default" formatter = "TSV" header = "0" uniqueRows = "0" count = "" datasetConfigVersion = "0.6" ><Dataset name = "oniloticus_gene_ensembl" interface = "default" ><Attribute name = "ensembl_transcript_id" /><Attribute name = "zfin_id_id" /><Attribute name = "wikigene_id" /></Dataset></Query>'
# awk '!$2{print $0,"NA";next}1' on_biomart4.txt | awk '!$3{print $0,"NA";next}1' > on_biomart4a.txt # fill the 2nd and 3rd column with NA if empty
#
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$3]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA";}}' on_biomart1a.txt on_biomart2a.txt > on_biomart1-2a.txt
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}' on_biomart3a.txt on_biomart1-2a.txt > on_biomart1-2-3a.txt
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA";}}' on_biomart4a.txt on_biomart1-2-3a.txt > on_biomart.tmp.txt
#
# printf 'ensembl_transcript_id\thgnc_symbol\tentrezgene_accession\trefseq_mrna_predicted\tensembl_gene_id\tensembl_gene_id_version\tensembl_transcript_id\tensembl_transcript_id_version\thgnc_id\tensembl_transcript_id\tuniprotswissprot\twikigene_name\tensembl_transcript_id\tzfin_id_id\twikigene_id\n' > biomart_headers # NOTE - many of these cols will get removed later
# # printf 'ensembl_gene_id\tensembl_gene_id_version\tensembl_transcript_id\tensembl_transcript_id_version\thgnc_id\tensembl_transcript_id\thgnc_symbol\tentrezgene_accession\trefseq_mrna_predicted\tensembl_transcript_id\tuniprotswissprot\twikigene_name\tensembl_transcript_id\tzfin_id_id\twikigene_id\n' > biomart_headers
# cat biomart_headers on_biomart.tmp.txt | awk '{print $1,$2,$3,$4,$5,$6,$8,$9,$11,$12,$14,$15}' OFS='\t' | awk '{print $5,$6,$1,$7,$8,$2,$3,$4,$9,$10,$11,$12}' OFS='\t' > on_biomart.txt

# Ac-3. awk match files '$file1' and '$file2' above to create two files:

# Ac-3a. One tab delimited file WITH HEADERS > ${Mz,Pn,Ab,Nb,On}ggenaltsv (these are stored in the species gtf dir), and
sed 's/.gtf/.genealias.txt.tmp1/g' $antfiles | grep -v $removesp | sort -u > $processggenaltsv

while read -r i; do
  echo ${i}_biomart.txt >> $biomartfiles.tmp
done < $biomartspecies
sort -u $biomartfiles.tmp > $biomartfiles; rm $biomartfiles.tmp

while read -u 3 -r file1 && read -u 4 -r file2
do
  awk 'BEGIN{OFS="\t"}NR==FNR{a[$1]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA";}}' ${file2} ${file1} | awk '{print $1,$14,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12}' OFS='\t' > $(echo "${file2}" | sed 's/.txt.tmp1/.tsv/g')
done 3<$biomartfiles 4<$processggenaltsv

Nbggenaltsvtmp=$(echo "$annotNbg" | sed 's/.gtf/.genealias.txt.tmp1/g'); cp $Nbggenaltsvtmp $Nbggenaltsv # just copy the tmp1 file and rename for this (since no biomart db exists)

# Ac-3b. Using the file from 'Ac-3a' above, prepare the gene alias files with correct format (plus ensure to exclude any NA/na columns)
# example format (3 col, tab delimited)
# ENSDARG00000031971      kdelc1  ENSDARG00000031971&kdelc1&393905&Dr.82452
# ENSG00000175899 A2M     HGNC:7&A2M&FWP007&S863-7&CPAMD5&BX647329&X68728&M11313&2&MGI:2449119&2408344&9697696&NM_000014&CCDS44827&OTTHUMG00000150267&2&P01023&ENSG00000175899

awk 'NR>1 {print $1,$2,$1"&"$2}' OFS='\t' $Nbggenaltsv | sed 's/\&NA//g' > $Nbggenal

# merge rows with same first column (ensembl_gene_id) and obtain unique cells in each row only for the output
sed 's/.gtf/.genealias.tsv/g' $antfiles | grep -v $removesp | sort -u > $processggenaltsv2

while read -r i; do
  awk -F'\t' 'NF>1{a[$1] = a[$1]"\t"$0};END{for(i in a)print i"\t"a[i]}' ${i} |
  awk '{ n=split($0,a,FS); $0=""; j=1; delete u; for (i=1; i<=n; i++) if (!u[a[i]]++) $(j++) = a[i]; print }' |
  sed 's/NA//g' > ${i}.tmpfile0
  awk '{print $1,$2}' OFS='\t' ${i}.tmpfile0 > ${i}.tmpfile1
  sed 's/ /\&/g' ${i}.tmpfile0 > ${i}.tmpfile2
  paste ${i}.tmpfile1 ${i}.tmpfile2 | awk '{print $1,$2,$3}' OFS='\t' > $(echo "${i}" | sed 's/.tsv/.txt/g')
  rm ${i}.tmpfile*
done < $processggenaltsv2

sed 's/.tsv/.txt/g' $processggenaltsv2 > $genalpaths
echo $(ls -1 $Nbggenal) >> $genalpaths

while read -r d; do
# for d in "$Mzgannot" "$Pngannot" "$Abgannot" "$Nbgannot" "$Ongannot"; do
  rm $(echo "${d}" | sed 's/.gtf/.genealias.txt.tmp1/g')
done < $antfiles

# B. Create data.config.user file with species specific entries
# see this for using own motifs: https://www.regulatory-genomics.org/motif-analysis/additional-motif-data/
# When RGT is installed, it will automatically create a folder to store additional data (default: ~/rgtdata).
# Within the subfolder motifs, files related to the motif analysis tool will be added: position frequency matrices (describing transcription factor motifs), files needed for the HTML report, etc

echo "$rgtidsp1" >> $rgtdatapath/data.config.user
echo "genome: $FAMzg" >> $rgtdatapath/data.config.user
echo "chromosome_sizes: $Mzgchr" >> $rgtdatapath/data.config.user
echo "genes_Gencode: $MzggenGC" >> $rgtdatapath/data.config.user
echo "genes_RefSeq: $MzggenRS" >> $rgtdatapath/data.config.user
echo "annotation: $annotMzg" >> $rgtdatapath/data.config.user
echo "gene_alias: $Mzggenal" >> $rgtdatapath/data.config.user
printf '\n' >> $rgtdatapath/data.config.user

echo "$rgtidsp2" >> $rgtdatapath/data.config.user
echo "genome: $FAPng" >> $rgtdatapath/data.config.user
echo "chromosome_sizes: $Pngchr" >> $rgtdatapath/data.config.user
echo "genes_Gencode: $PnggenGC" >> $rgtdatapath/data.config.user
echo "genes_RefSeq: $PnggenRS" >> $rgtdatapath/data.config.user
echo "annotation: $annotPng" >> $rgtdatapath/data.config.user
echo "gene_alias: $Pnggenal" >> $rgtdatapath/data.config.user
printf '\n' >> $rgtdatapath/data.config.user

echo "$rgtidsp3" >> $rgtdatapath/data.config.user
echo "genome: $FAAbg" >> $rgtdatapath/data.config.user
echo "chromosome_sizes: $Abgchr" >> $rgtdatapath/data.config.user
echo "genes_Gencode: $AbggenGC" >> $rgtdatapath/data.config.user
echo "genes_RefSeq: $AbggenRS" >> $rgtdatapath/data.config.user
echo "annotation: $annotAbg" >> $rgtdatapath/data.config.user
echo "gene_alias: $Abggenal" >> $rgtdatapath/data.config.user
printf '\n' >> $rgtdatapath/data.config.user

echo "$rgtidsp4" >> $rgtdatapath/data.config.user
echo "genome: $FANbg" >> $rgtdatapath/data.config.user
echo "chromosome_sizes: $Nbgchr" >> $rgtdatapath/data.config.user
echo "genes_Gencode: $NbggenGC" >> $rgtdatapath/data.config.user
echo "genes_RefSeq: $NbggenRS" >> $rgtdatapath/data.config.user
echo "annotation: $annotNbg" >> $rgtdatapath/data.config.user
echo "gene_alias: $Nbggenal" >> $rgtdatapath/data.config.user
printf '\n' >> $rgtdatapath/data.config.user

echo "$rgtidsp5" >> $rgtdatapath/data.config.user
echo "genome: $FAOng" >> $rgtdatapath/data.config.user
echo "chromosome_sizes: $Ongchr" >> $rgtdatapath/data.config.user
echo "genes_Gencode: $OnggenGC" >> $rgtdatapath/data.config.user
echo "genes_RefSeq: $OnggenRS" >> $rgtdatapath/data.config.user
echo "annotation: $annotOng" >> $rgtdatapath/data.config.user
echo "gene_alias: $Onggenal" >> $rgtdatapath/data.config.user
printf '\n' >> $rgtdatapath/data.config.user

# C. Create an array to work on files of each species

# Create narrowPeak file paths for each species - can change species IDs for footprinting here
for Afpsp in "${!fpsp@}"; do
  # echo "$Afpsp is set to ${!Afpsp}"
  ls -1 $idrdir/"${!Afpsp}"*.final.narrowPeak >> $tffprdir/"${!Afpsp}"peakpaths.txt
done

# this will assign peakpaths files to ${fpsp@}peaks variables e.g. $Abpeaks
for Bfpsp in "${!fpsp@}"; do
  # echo "$Bfpsp is set to ${!Bfpsp}"
  eval "${!Bfpsp}"peaks=${tffprdir}/"${!Bfpsp}"peakpaths.txt
done

# get the total number of files for array and assign to variables e.g. $Abpeararrayend for each species, and then assign script variables for running footprinting e.g. $AbFPscript
for Cfpsp in "${!fpsp@}"; do
  # echo "$Cfpsp is set to ${!Cfpsp}"
  eval "${!Cfpsp}"peaks=${tffprdir}/"${!Cfpsp}"peakpaths.txt
  eval "${!Cfpsp}"peararrayend=$(wc -l "${!Cfpsp}"peakpaths.txt | awk -v e="$e" '{print ($1 - e)}')
  eval "${!Cfpsp}"FPscript="${!Cfpsp}"_TFfp.sh
done

# D. run TF footprinting and creating signal tracks e.g. https://www.regulatory-genomics.org/hint/tutorial/

# Da. Prepare PWM files/folders and data.config.user to use own motifs and genome info

# ## Daa. Prepare and move pwm's to specfic path - NOTE: this is relatively hardcoded and thus needs changing for future work
#
# # split to create multiple meme files
#
# for Apwmsp in "${!pwmsp@}"; do
#   # echo "$Apwmsp is set to ${!Apwmsp}"
#   mkdir -p $rgtdatapath/motifs/cichlid"${!Apwmsp}"CSsp
#   # python3 $splitmeme -i /tgac/workarea/group-vh/Tarang/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/2a_CS_"${!Apwmsp}".meme -o $rgtdatapath/motifs/cichlid"${!Apwmsp}"CSsp/tmp -t CS -s "${!Apwmsp}"
#   # rm $rgtdatapath/motifs/cichlid"${!Apwmsp}"CSsp/tmp/MEME_CS_"${!Apwmsp}".meme
# done
#
# mkdir -p $rgtdatapath/motifs/cichlidCW
# # python3 $splitmeme -i /tgac/workarea/group-vh/Tarang/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/2b_CW_mz.meme -o $rgtdatapath/motifs/cichlidCW/tmp -t CW -s CW
# # rm $rgtdatapath/motifs/cichlidCW/tmp/MEME_CW_CW.meme
#
# mkdir -p $rgtdatapath/motifs/cichlidJASPAR
# # python3 $splitmeme -i /tgac/workarea/group-vh/Tarang/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/2c_JASPAR_mz.meme -o $rgtdatapath/motifs/cichlidJASPAR/tmp -t CJP -s CJP
# # rm $rgtdatapath/motifs/cichlidJASPAR/tmp/MEME_CJP_CJP.meme
#
# # .. Need to convert meme format to JASPAR2016 format - use R universal matrix
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/{CS,CW,JP}/{mz,pn,ab,nb,on}/*.meme; do
#   Rscript ~/github/ATAC_bioinformatics/meme2jaspar.R -i ${i} -o "$(echo ${i} | sed 's/.meme/.tmp.pwm/g')"
# done
#
# # .. convert JASPAR 2016 CFM PWM to JASPAR OLD PFM format by removing header, nucleotides and square brackets
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/{CS,CW}/{mz,pn,ab,nb,on}/*.tmp.pwm; do
#   awk '!/^>/' ${i} | sed 's/A \[  //g' | sed 's/T \[  //g' | sed 's/C \[  //g' | sed 's/G \[  //g' | sed 's/ \]//g' | grep . > "$(echo ${i} | sed 's/.tmp.pwm/.pwm/g')"
#   rm ${i}
# done
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/JP/mz/*.tmp.pwm; do
#   awk '!/^>/' ${i} | sed 's/A \[  //g' | sed 's/T \[  //g' | sed 's/C \[  //g' | sed 's/G \[  //g' | sed 's/ \]//g' | grep . > "$(echo ${i} | sed 's/.tmp.pwm/.pwm/g')"
#   rm ${i}
# done
#
# # .. move new PWMs to sub dirs
# mkdir -p /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/{CS,CW}/{mz,pn,ab,nb,on}/JPoldPWMformat
# mkdir -p /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/JP/mz/JPoldPWMformat
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/{CS,CW}/{mz,pn,ab,nb,on}; do
#   mv ${i}/*.pwm ${i}/JPoldPWMformat
# done
#
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/JP/mz; do
#   mv ${i}/*.pwm ${i}/JPoldPWMformat
# done
#
#
# # .. move the created PWM to HPC
# for i in mz pn ab nb on; do
#   cp -r /tgac/workarea/group-vh/Tarang/ATACseq/motifs/CS/${i}/JPoldPWMformat/* $rgtdatapath/motifs/cichlid"${i}"CSsp
# done
#
# cp -r /tgac/workarea/group-vh/Tarang/ATACseq/motifs/CW/mz/JPoldPWMformat/* $rgtdatapath/motifs/cichlidCW
# cp -r /tgac/workarea/group-vh/Tarang/ATACseq/motifs/JP/mz/JPoldPWMformat/* $rgtdatapath/motifs/cichlidJASPAR
#
# # .. convert preexisting *.eps logos to *.png for cichlid PWMs and move to $rgtdatapath/motifs/logos
# # use imagemagick: 'brew install imagemagick'; 'brew install ghostscript'
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/CS/{mz,pn,ab,nb,on}/logos; do
#   mkdir ${i}/png
# done
#
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/CS/{mz,pn,ab,nb,on}/logos/*.eps; do
#   convert -density 150 ${i} $(echo ${i} | sed 's/.eps/.png/g')
# done
#
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/CS/{mz,pn,ab,nb,on}/logos; do
#   mv ${i}/*.png ${i}/png
# done
#
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/{CW,JP}/mz/logos; do
#   mkdir ${i}/png
# done
#
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/{CW,JP}/mz/logos/*.eps; do
#   convert -density 150 ${i} $(echo ${i} | sed 's/.eps/.png/g')
# done
#
# for i in /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/{CW,JP}/mz/logos; do
#   mv ${i}/*.png ${i}/png
# done
#
# # copy to group workarea on HPC and then to $rgtdatapath/logos (once logo generation has ran)
# for i in mz pn ab nb on; do
#   mkdir -p $rgtdatapath/logos/cichlid"${i}"CSsp
#   cp -r /tgac/workarea/group-vh/Tarang/ATACseq/motifs/CS/${i}/logos/* $rgtdatapath/logos/cichlid"${i}"CSsp
# done
#
# mkdir -p $rgtdatapath/logos/cichlidCW; cp -r /tgac/workarea/group-vh/Tarang/ATACseq/motifs/CW/mz/logos/* $rgtdatapath/logos/cichlidCW
# mkdir -p $rgtdatapath/logos/cichlidJASPAR; cp -r /tgac/workarea/group-vh/Tarang/ATACseq/motifs/JP/mz/logos/* $rgtdatapath/logos/cichlidJASPAR
#
#
# # .. Consider making the tab delimited *.mtf files for selected motifs: see https://www.regulatory-genomics.org/motif-analysis/additional-motif-data/
# # AHR	AHR_HUMAN.H11MO.0.B	0.B	AHR	PAS domain factors	P35869	Integrative	vertebrates	Homo sapiens	2.8475,6.6065,8.544,11.1115,11.6185,12.7235
# # The first field simply the clean “name” of the motif.
# # The second field is the full, unique, original name of the motif.
# # The third field is the version of this motif (it changes slightly across different repositories)
# # The fourth field is the TF gene name, the so-called “gene symbol”
# # The fifth field is the so-called “motif family”, a description that varies a lot across repositories. CHANGED THIS FOR ENSMUS ID
# # The sixth field is one or more Uniprot identifiers
# # The seventh field is the data source (Chip-Seq, Selex, Integrative)
# # The eight field is the taxonomic group
# # The ninth field is the species (usually the full name, eg “Home sapiens”, not “hs”)
# # The tenth field is a list of precomputed thresholds for several FPR values: 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001
# # NOTE: The good news is that you don’t need to set them all. Any field you do not want to set you can replace with a single dot.
#
# # .. cichlid{mz,pn,ab,nb,on}CSsp mtf files
# cichlidmeta=/Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/cichlid_allMm_motifs_meta_info.txt
# JPv2018map=/Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/May2019_ReviewerComments/1.1b.RetinaMotifDivergence/JASPAR_Vertebrates_2018_motifname.OGID.txt
# ogids=/Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/OGIDS.txt5
#
# cd /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/CS/mz/JPoldPWMformat
# ls -1 *.pwm | awk '{print $1,$1}' OFS='\t' | awk -F'_' '{print $0,$7}' OFS='\t' | awk '{print $1,$3}' OFS='\t' | awk -F"\t" '{gsub(".ig","",$2)}1' OFS='\t' > cichlidmzCSsp.mtf.tmp1
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$4]=$0;next}{if(a[$2]){print $0,a[$2];}else{print $0,".","NULL",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".";}}' $JPv2018map cichlidmzCSsp.mtf.tmp1 | awk '{print $2,$4"_CS_"$2,$1,"CS_v1",$4,$20,".","Integrative","vertebrates","Metriaclima_zebra","."}' OFS='\t' > cichlidmzCSsp.mtf.tmp2
#
# # # pull out all gene symbols in $cichlidmeta file using ensemblID
# # while read -r a b c d e f g h i j k; do
# #   # echo $e
# #   grep -A 25 -B 3 -wiF ${f} $cichlidmeta | grep 'Gene symbol\|Ensembl id' >> cichlidmzCSsp.mtf.tmp3
# # done < cichlidmzCSsp.mtf.tmp2
# # # convert the above output from rows to two columns
# # {
# # awk -F: 'BEGIN{ sl="Gene symbol"}
# #          $1~sl && head == 1 { head=0; exit 0}
# #          $1~sl && head == 0 { head=1; }
# #          head == 1 {
# #              gsub(/^[ \t]+/,"",$1);   # remove leading  spaces
# #              gsub(/[ \t]+$/,"",$1);   # remove trailing spaces
# #              printf( "%s\t", $1)
# #          }
# #          ' cichlidmzCSsp.mtf.tmp3
# # #echo
# # awk -F: 'BEGIN { sl="Gene symbol"}
# #          $1~sl { printf( "%s\n", "") }
# #          {
# #              gsub(/^[ \t]+/,"",$2);   # remove leading  spaces
# #              gsub(/[ \t]+$/,"",$2);   # remove trailing spaces
# #              printf( "%s\t", $2)
# #          }
# #          ' cichlidmzCSsp.mtf.tmp3
# # echo
# # } | column -t -s "$(printf '%b' '\t')" > cichlidmzCSsp.mtf.tmp4
# #
# # awk 'BEGIN{OFS="\t"}NR==FNR{a[$2]=$0;next}{if(a[$5]){print $0,a[$5];}else{print $0,".","NULL",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".","NO","NO";}}' cichlidmzCSsp.mtf.tmp4 cichlidmzCSsp.mtf.tmp2 | awk '{print $4"_CS_"$2,$1,"CS_v1",$4,$20,".","Integrative","vertebrates","Metriaclima_zebra","."}' OFS='\t' > cichlidmzCSsp.mtf.tmp5
#
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$2]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA";}}' $ogids cichlidmzCSsp.mtf.tmp2 | awk '{if($5 == "NULL")print $26"_CS_"$1,$3,$4,$26,$6,$7,$8,$9,$10,$11;else print $2,$3,$4,$5,$6,$7,$8,$9,$10,$11;}' OFS='\t' > cichlidmzCSsp.mtf
# rm cichlidmzCSsp.mtf.tmp*
#
# cd /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/CS/pn/JPoldPWMformat
# ls -1 *.pwm | awk '{print $1,$1}' OFS='\t' | awk -F'_' '{print $0,$7}' OFS='\t' | awk '{print $1,$3}' OFS='\t' | awk -F"\t" '{gsub(".ig","",$2)}1' OFS='\t' > cichlidpnCSsp.mtf.tmp1
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$5]=$0;next}{if(a[$2]){print $0,a[$2];}else{print $0,".","NULL",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".";}}' $JPv2018map cichlidpnCSsp.mtf.tmp1 | awk '{print $2,$4"_CS_"$2,$1,"CS_v1",$4,$20,".","Integrative","vertebrates","Pundamilia_nyererei","."}' OFS='\t' > cichlidpnCSsp.mtf.tmp2
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$3]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA";}}' $ogids cichlidpnCSsp.mtf.tmp2 | awk '{if($5 == "NULL")print $26"_CS_"$1,$3,$4,$26,$6,$7,$8,$9,$10,$11;else print $2,$3,$4,$5,$6,$7,$8,$9,$10,$11;}' OFS='\t' > cichlidpnCSsp.mtf
# rm cichlidpnCSsp.mtf.tmp*
#
# cd /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/CS/ab/JPoldPWMformat
# ls -1 *.pwm | awk '{print $1,$1}' OFS='\t' | awk -F'_' '{print $0,$7}' OFS='\t' | awk '{print $1,$3}' OFS='\t' | awk -F"\t" '{gsub(".ig","",$2)}1' OFS='\t' > cichlidabCSsp.mtf.tmp1
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$6]=$0;next}{if(a[$2]){print $0,a[$2];}else{print $0,".","NULL",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".";}}' $JPv2018map cichlidabCSsp.mtf.tmp1 | awk '{print $2,$4"_CS_"$2,$1,"CS_v1",$4,$20,".","Integrative","vertebrates","Astatotilapia_burtoni","."}' OFS='\t' > cichlidabCSsp.mtf.tmp2
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$4]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA";}}' $ogids cichlidabCSsp.mtf.tmp2 | awk '{if($5 == "NULL")print $26"_CS_"$1,$3,$4,$26,$6,$7,$8,$9,$10,$11;else print $2,$3,$4,$5,$6,$7,$8,$9,$10,$11;}' OFS='\t' > cichlidabCSsp.mtf
# rm cichlidabCSsp.mtf.tmp*
#
# cd /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/CS/nb/JPoldPWMformat
# ls -1 *.pwm | awk '{print $1,$1}' OFS='\t' | awk -F'_' '{print $0,$7}' OFS='\t' | awk '{print $1,$3}' OFS='\t' | awk -F"\t" '{gsub(".ig","",$2)}1' OFS='\t' > cichlidnbCSsp.mtf.tmp1
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$7]=$0;next}{if(a[$2]){print $0,a[$2];}else{print $0,".","NULL",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".";}}' $JPv2018map cichlidnbCSsp.mtf.tmp1 | awk '{print $2,$4"_CS_"$2,$1,"CS_v1",$4,$20,".","Integrative","vertebrates","Neolamprologus_brichardi","."}' OFS='\t' > cichlidnbCSsp.mtf.tmp2
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$5]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA";}}' $ogids cichlidnbCSsp.mtf.tmp2 | awk '{if($5 == "NULL")print $26"_CS_"$1,$3,$4,$26,$6,$7,$8,$9,$10,$11;else print $2,$3,$4,$5,$6,$7,$8,$9,$10,$11;}' OFS='\t' > cichlidnbCSsp.mtf
# rm cichlidnbCSsp.mtf.tmp*
#
# cd /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/CS/on/JPoldPWMformat
# ls -1 *.pwm | awk '{print $1,$1}' OFS='\t' | awk -F'_' '{print $0,$7}' OFS='\t' | awk '{print $1,$3}' OFS='\t' | awk -F"\t" '{gsub(".ig","",$2)}1' OFS='\t' > cichlidonCSsp.mtf.tmp1
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$8]=$0;next}{if(a[$2]){print $0,a[$2];}else{print $0,".","NULL",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".";}}' $JPv2018map cichlidonCSsp.mtf.tmp1 | awk '{print $2,$4"_CS_"$2,$1,"CS_v1",$4,$20,".","Integrative","vertebrates","Oreochromis_niloticus","."}' OFS='\t' > cichlidonCSsp.mtf.tmp2
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$6]=$0;next}{if(a[$1]){print $0,a[$1];}else{print $0,"NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA";}}' $ogids cichlidonCSsp.mtf.tmp2 | awk '{if($5 == "NULL")print $26"_CS_"$1,$3,$4,$26,$6,$7,$8,$9,$10,$11;else print $2,$3,$4,$5,$6,$7,$8,$9,$10,$11;}' OFS='\t' > cichlidonCSsp.mtf
# rm cichlidonCSsp.mtf.tmp*
#
# cp /tgac/workarea/group-vh/Tarang/ATACseq/motifs/cichlid*CSsp.mtf $rgtdatapath/motifs/
#
#
# # .. cichlidCW mtf file
# cd /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/CW/mz/JPoldPWMformat
# JPv2018map=/Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/May2019_ReviewerComments/1.1b.RetinaMotifDivergence/JASPAR_Vertebrates_2018_motifname.OGID.txt
# ls -1 *.pwm | awk '{print $1,$1}' OFS='\t' | awk -F'_' '{print $0,$20}' OFS='\t' | awk '{print $1,$3}' OFS='\t' > cichlidCW.mtf.tmp1
# awk 'BEGIN{OFS="\t"}NR==FNR{a[$18]=$0;next}{if(a[$2]){print $0,a[$2];}else{print $0,".","NULL",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".",".";}}' $JPv2018map cichlidCW.mtf.tmp1 | awk '{print $4"_CW_"$2,$1,"CW_v1",$4,".",".","Integrative","vertebrates","Cichlidae","."}' OFS='\t' > cichlidCW.mtf
# rm cichlidCW.mtf.tmp1
# # fill in some blanks manually by searching in other mapping file:
# # for i in ENSMUSG00000025025 ENSMUSG00000028023 ENSMUSG00000030087 ENSMUSG00000061911; do grep -A 25 -B 3 ${i} $cichlidmeta | grep 'Gene symbol\|Ensembl id'; done
# cp /tgac/workarea/group-vh/Tarang/ATACseq/motifs/cichlidCW.mtf $rgtdatapath/motifs/
#
#
#
# # .. cichlid JASPAR 2018 mtf file
# cd /Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/1.TFBSs_v2/FINAL_cichlidPWM_motifs/MouseDerived/JP/mz/JPoldPWMformat
# JPv2018map=/Users/mehtat/Documents/TGAC/Projects/Cichlid_GRNs/Arboretum_GT_v3/May2019_ReviewerComments/1.1b.RetinaMotifDivergence/JASPAR_Vertebrates_2018_motifname.OGID.txt
# awk '{print $1,$1,"JPv2018",$2,".",".","Integrative","vertebrates","Mus musculus","."}' OFS='\t' $JPv2018map > cichlidJASPAR.mtf
# cp /tgac/workarea/group-vh/Tarang/ATACseq/motifs/cichlidJASPAR.mtf $rgtdatapath/motifs/
#
#
# ## Dab. generate logos of above
# cd $rgtdatapath
#
#
# nano setuplogo.sh
#
# #!/bin/bash -e
# #SBATCH -p tgac-short # partition (queue)
# #SBATCH -N 1 # number of nodes
# #SBATCH -n 1 # number of tasks
# #SBATCH --array=0-4
# #SBATCH --mem-per-cpu 12000
# #SBATCH -t 0-00:45
# #SBATCH --mail-type=ALL # notifications for job done & fail
# #SBATCH --mail-user=Tarang.Mehta@earlham.ac.uk # send-to address
# #SBATCH -o slurm.%N.%j.out # STDOUT
# #SBATCH -e slurm.%N.%j.err # STDERR
#
# echo 'hocomoco' > motiflist
# echo 'jaspar_plants' >> motiflist
# echo 'jaspar_vertebrates' >> motiflist
# echo 'uniprobe_primary' >> motiflist
# echo 'uniprobe_secondary' >> motiflist
#
# mapfile -t motiflist < motiflist
#
# # NOTE: the python script requires an active internet connection to access weblogo
# USERNAME=mehtat
# HOSTNAME="software"
# PWD=$(pwd)
# SCRIPT="cd ${PWD}; python3 setupLogoData.py ${motiflist[${SLURM_ARRAY_TASK_ID}]}; exit" # generate logos for all motifs subdirs
# ssh -o StrictHostKeyChecking=no -l ${USERNAME} ${HOSTNAME} "${SCRIPT}"
#
# # run the above
# sbatch setuplogo.sh
#
# # insert above data to config file
# echo '[MotifData]' >> $rgtdatapath/data.config.user
# echo "pwm_dataset: motifs" >> $rgtdatapath/data.config.user # Contains the path to the motif position weight matrices (PWM) repositories.
# echo "logo_dataset: logos" >> $rgtdatapath/data.config.user # Contains the path to the logo graphs (graphical depiction of PWMs). Look here: http://www.regulatory-genomics.org/additional-motif-data/
# echo "repositories: cichlidmzCSsp, cichlidpnCSsp, cichlidabCSsp, cichlidnbCSsp, cichlidonCSsp, cichlidCW, cichlidJASPAR, jaspar_vertebrates, hocomoco, jaspar_plants, uniprobe_primary, uniprobe_secondary" >> $rgtdatapath/data.config.user #  	The PWM repositories that will be used in the analyses. It is a comma-separated list of folders inside <pwm_dataset> (see this option above) folder.


# Db. Prepare scripts for footprinting
for Dfpsp in "${!fpsp@}"; do
  # echo "$Dfpsp is set to ${!Dfpsp}"
  echo '#!/bin/bash -e' > "${!Dfpsp}"'_TFfp.sh'
  echo '#SBATCH -p tgac-medium # partition (queue)' >> "${!Dfpsp}"'_TFfp.sh'
  echo '#SBATCH -N 1 # number of nodes' >> "${!Dfpsp}"'_TFfp.sh'
  echo '#SBATCH -n 1 # number of tasks' >> "${!Dfpsp}"'_TFfp.sh'
  echo '#SBATCH --array=0-'"$(eval "echo \$"${!Dfpsp}"peararrayend")" >> "${!Dfpsp}"'_TFfp.sh'
  echo '#SBATCH --mem-per-cpu 32000' >> "${!Dfpsp}"'_TFfp.sh'
  echo '#SBATCH -t 0-05:59' >> "${!Dfpsp}"'_TFfp.sh'
  echo '#SBATCH --mail-type=ALL # notifications for job done & fail' >> "${!Dfpsp}"'_TFfp.sh'
  echo '#SBATCH --mail-user=Tarang.Mehta@earlham.ac.uk # send-to address' >> "${!Dfpsp}"'_TFfp.sh'
  echo '#SBATCH -o slurm.%N.%j.out # STDOUT' >> "${!Dfpsp}"'_TFfp.sh'
  echo '#SBATCH -e slurm.%N.%j.err # STDERR' >> "${!Dfpsp}"'_TFfp.sh'
  printf '\n' >> "${!Dfpsp}"'_TFfp.sh'
  echo "ml samtools/1.7" >> "${!Dfpsp}"'_TFfp.sh'
  echo 'export PATH="$PATH:/hpc-home/mehtat/.local/bin/"' >> "${!Dfpsp}"'_TFfp.sh'
  printf '\n' >> "${!Dfpsp}"'_TFfp.sh'
  echo '# 0. mapfile the narrowPeak files' >> "${!Dfpsp}"'_TFfp.sh'
  echo "mapfile -t ${!Dfpsp}peakarray < $(eval "echo \$"${!Dfpsp}peaks) # assign files to variable for array" >> "${!Dfpsp}"'_TFfp.sh'
  echo 'echo "# 0. mapfile the narrowPeak files ~~ DONE"' >> "${!Dfpsp}"'_TFfp.sh'
  printf '\n' >> "${!Dfpsp}"'_TFfp.sh'
  echo '# 1. prepare a prefix file using the peaks file e.g. $Abpeaks' >> "${!Dfpsp}"'_TFfp.sh'
  echo "${!Dfpsp}prefix=(${!Dfpsp}prefixes.txt)" >> "${!Dfpsp}"'_TFfp.sh'
  echo "awk -F'/' ' { print "'$NF } '"' $(eval "echo \$"${!Dfpsp}peaks) | sed 's/_peaks.final.narrowPeak//g' > \$${!Dfpsp}prefix" >> "${!Dfpsp}"'_TFfp.sh'
  echo 'echo "# 1. prepare a prefix file using the peaks file e.g. $Abpeaks ~~ DONE"' >> "${!Dfpsp}"'_TFfp.sh'
  printf '\n' >> "${!Dfpsp}"'_TFfp.sh'
  echo '# 2. mapfile the above file' >> "${!Dfpsp}"'_TFfp.sh'
  echo "mapfile -t ${!Dfpsp}prefixes < \$${!Dfpsp}prefix" >> "${!Dfpsp}"'_TFfp.sh'
  echo 'echo "# 2. mapfile the above file ~~ DONE"' >> "${!Dfpsp}"'_TFfp.sh'
  printf '\n' >> "${!Dfpsp}"'_TFfp.sh'
  echo '# 3. prepare another file to iterate the input BAM files (can use the array on this) - echo the *peakarray and sed replace to prepare the path (will have to use the mapfile from above to add the prefix to peak calling folder)' >> "${!Dfpsp}"'_TFfp.sh'
  echo "${!Dfpsp}BAM=(${!Dfpsp}inputBAM.txt)" >> "${!Dfpsp}"'_TFfp.sh'
  echo 'echo '"\${${!Dfpsp}"'peakarray[${SLURM_ARRAY_TASK_ID}]} | sed "s|'"$idrdir|$scripts/\${${!Dfpsp}"'prefixes[${SLURM_ARRAY_TASK_ID}]}/5.peak_calling|g" | sed '"'s/_peaks.final.narrowPeak/.nochrM.nodup.filt.querysorted.bam/g' >> \$${!Dfpsp}BAM" >> "${!Dfpsp}"'_TFfp.sh'
  echo 'echo "# 3. prepare another file to iterate the input BAM files (can use the array on this) - echo the *peakarray and sed replace to prepare the path (will have to use the mapfile from above to add the prefix to peak calling folder) ~~ DONE"' >> "${!Dfpsp}"'_TFfp.sh'
  printf '\n' >> "${!Dfpsp}"'_TFfp.sh'
  echo '# 4. mapfile the file from above' >> "${!Dfpsp}"'_TFfp.sh'
  echo "mapfile -t ${!Dfpsp}BAM < \$${!Dfpsp}BAM" >> "${!Dfpsp}"'_TFfp.sh'
  echo 'echo "# 4. mapfile the file from above ~~ DONE"' >> "${!Dfpsp}"'_TFfp.sh'
  printf '\n' >> "${!Dfpsp}"'_TFfp.sh'
  echo '# 5. run samtools sort and index and drop in this folder' >> "${!Dfpsp}"'_TFfp.sh'
  echo 'samtools sort '"\${${!Dfpsp}"'BAM[${SLURM_ARRAY_TASK_ID}]} -o "$(basename "'"\${${!Dfpsp}"'BAM[${SLURM_ARRAY_TASK_ID}]}" .querysorted.bam).sorted.bam"' >> "${!Dfpsp}"'_TFfp.sh'
  echo 'samtools index "$(basename "'"\${${!Dfpsp}"'BAM[${SLURM_ARRAY_TASK_ID}]}" .querysorted.bam).sorted.bam"' >> "${!Dfpsp}"'_TFfp.sh'
  echo 'echo "# 5. run samtools sort and index and drop in this folder ~~ DONE"' >> "${!Dfpsp}"'_TFfp.sh'
  printf '\n' >> "${!Dfpsp}"'_TFfp.sh'
  echo '# A. call footprints - input BAM is the query indexed and sorted of ATAC reads aligned to genome, mtDNA removed' >> "${!Dfpsp}"'_TFfp.sh'
  echo "mkdir -p $tffprdir/${pwmsp3}_fp" >> "${!Dfpsp}"'_TFfp.sh'
  echo 'organism=\$"$(echo '"$Dfpsp | sed 's/[^0-9]//g' | sed 's/^/rgtidsp/' | sed 's/"'$/a/'"')"'"' >> "${!Dfpsp}"'_TFfp.sh'
  echo 'output=\$"$(echo '"$Dfpsp | sed 's/[^0-9]//g' | sed 's/^/pwmsp/')"'"' >> "${!Dfpsp}"'_TFfp.sh'
  echo 'rgt-hint footprinting --atac-seq --paired-end --organism=$(eval echo $organism) --output-location='"$tffprdir"'/$(eval echo $output)_fp --output-prefix='"\${${!Dfpsp}"'prefixes[${SLURM_ARRAY_TASK_ID}]} "$(basename "'"\${${!Dfpsp}"'BAM[${SLURM_ARRAY_TASK_ID}]}" .querysorted.bam).sorted.bam" '"\${${!Dfpsp}"'peakarray[${SLURM_ARRAY_TASK_ID}]}' >> "${!Dfpsp}"'_TFfp.sh'
  echo 'echo "# A. call footprints - input BAM is the query indexed and sorted of ATAC reads aligned to genome, mtDNA removed ~~ DONE"' >> "${!Dfpsp}"'_TFfp.sh'
  printf '\n' >> "${!Dfpsp}"'_TFfp.sh'
  echo '# B. outputs signals for visualization in a genome browser' >> "${!Dfpsp}"'_TFfp.sh'
  echo "${!Dfpsp}signalprefix=(${!Dfpsp}signalprefixes.txt)" >> "${!Dfpsp}"'_TFfp.sh'
  echo "sed 's"'/$/_BC/'"g' \$${!Dfpsp}prefix > \$${!Dfpsp}signalprefix" >> "${!Dfpsp}"'_TFfp.sh'
  echo "mapfile -t ${!Dfpsp}signalprefix < \$${!Dfpsp}signalprefix" >> "${!Dfpsp}"'_TFfp.sh'
  echo 'rgt-hint tracks --bc --bigWig --organism=$(eval echo $organism) $(basename "'"\${${!Dfpsp}"'BAM[${SLURM_ARRAY_TASK_ID}]}" .querysorted.bam).sorted.bam" '"\${${!Dfpsp}"'peakarray[${SLURM_ARRAY_TASK_ID}]} --output-prefix='"\${${!Dfpsp}"'signalprefix[${SLURM_ARRAY_TASK_ID}]}' >> "${!Dfpsp}"'_TFfp.sh'
  echo 'echo "# B. outputs signals for visualization in a genome browser ~~ DONE"' >> "${!Dfpsp}"'_TFfp.sh'
  printf '\n' >> "${!Dfpsp}"'_TFfp.sh'
  echo '# C. find associated TFs' >> "${!Dfpsp}"'_TFfp.sh'
  echo 'rgt-motifanalysis matching --filter "database:cichlid$(eval echo $output)CSsp, cichlidCW, cichlidJASPAR, jaspar_vertebrates, hocomoco" --organism=$(eval echo $organism) --input-files '"$tffprdir"'/$(eval echo $output)'"_fp"'/'"\${${!Dfpsp}"'prefixes[${SLURM_ARRAY_TASK_ID}]}.bed' >> "${!Dfpsp}"'_TFfp.sh'
  echo 'echo "# C. find associated TFs ~~ DONE"' >> "${!Dfpsp}"'_TFfp.sh'
done

# scripts=(/ei/projects/9/9e238063-c905-4076-a975-f7c7f85dbd56/data/ATACseq/3.run2)
# ml samtools/1.7
# # idrdir=($scripts/1.IDR)
# idrdir=($scripts/idr_test) # THIS NEEDS CHANGING TO ABOVE PATH FOR FINAL SCRIPT
#
# # 0. mapfile the narrowPeak files
# mapfile -t Abpeakarray < $Abpeaks # assign files to variable for array
#
# # 1. prepare a prefix file using the peaks file e.g. $Abpeaks
# Abprefix=(Abprefixes.txt)
# awk -F'/' ' { print $NF } ' $Abpeaks | sed 's/_peaks.final.narrowPeak//g' > $Abprefix
#
# # 2. mapfile the above file
# mapfile -t Abprefixes < $Abprefix
#
# # 3. prepare another file to iterate the input BAM files (can use the array on this) - echo the Abpeakarray and sed replace to prepare the path (will have to use the mapfile from above to add the prefix to peak calling folder)
# AbBAM=(AbinputBAM.txt)
# echo ${Abpeakarray[${SLURM_ARRAY_TASK_ID}]} | sed "s|$idrdir|$scripts/${Abprefixes[${SLURM_ARRAY_TASK_ID}]}/5.peak_calling|g" | sed 's/_peaks.final.narrowPeak/.nochrM.nodup.filt.querysorted.bam/g' >> $AbBAM
# # echo "${Abpeakarray[0]}" | sed "s|$idrdir|$scripts/${Abprefixes[0]}/5.peak_calling|g" | sed 's/_peaks.final.narrowPeak/.nochrM.nodup.filt.querysorted.bam/g'
#
# # 4, mapfile the file from above
# mapfile -t AbBAM < $AbBAM
#
# # 5. run samtools sort and index and drop in this folder
# samtools sort "${AbBAM[${SLURM_ARRAY_TASK_ID}]}" -o "$(basename "${AbBAM[${SLURM_ARRAY_TASK_ID}]}" .querysorted.bam).sorted.bam"
# samtools index "$(basename "${AbBAM[${SLURM_ARRAY_TASK_ID}]}" .querysorted.bam).sorted.bam"
#
#
# # A. call footprints - input BAM is the query indexed and sorted of ATAC reads aligned to genome, mtDNA removed
# # export PATH="$PATH:/hpc-home/mehtat/.local/bin/rgt-TDF"
# # export PATH="$PATH:/hpc-home/mehtat/.local/bin/rgt-THOR"
# # export PATH="$PATH:/hpc-home/mehtat/.local/bin/rgt-filterVCF"
# # export PATH="$PATH:/hpc-home/mehtat/.local/bin/rgt-hint"
# # export PATH="$PATH:/hpc-home/mehtat/.local/bin/rgt-motifanalysis"
# # export PATH="$PATH:/hpc-home/mehtat/.local/bin/rgt-viz"
# # export PATH="$PATH:/hpc-home/mehtat/.local/bin/wigToBigWig"
# # export PATH="$PATH:/hpc-home/mehtat/.local/lib/python3.7/site-packages/rgt"
# # RGTDATA=(~/rgtdata)
# export PATH="$PATH:/hpc-home/mehtat/.local/bin/"
# mkdir -p $tffprdir/${pwmsp3}_fp
# rgt-hint footprinting --atac-seq --paired-end --organism=$rgtidsp3a --output-location=$tffprdir/${pwmsp3}_fp --output-prefix=${Abprefixes[${SLURM_ARRAY_TASK_ID}]} "$(basename "${AbBAM[${SLURM_ARRAY_TASK_ID}]}" .querysorted.bam).sorted.bam" ${Abpeakarray[${SLURM_ARRAY_TASK_ID}]}
#
# # B. outputs signals for visualization in a genome browser
# Absignalprefix=(Absignalprefixes.txt)
# sed 's/$/_BC/g' $Abprefix > $Absignalprefix
# mapfile -t Absignalprefix < $Absignalprefix
# rgt-hint tracks --bc --bigWig --organism=$rgtidsp3a "$(basename "${AbBAM[${SLURM_ARRAY_TASK_ID}]}" .querysorted.bam).sorted.bam" ${Abpeakarray[${SLURM_ARRAY_TASK_ID}]} --output-prefix=${Absignalprefix[${SLURM_ARRAY_TASK_ID}]}
#
# # C. find associated TFs
# rgt-motifanalysis matching --filter "database:cichlid${pwmsp3}CSsp, cichlidCW, cichlidJASPAR, jaspar_vertebrates, hocomoco" --organism=$rgtidsp3a --input-files $tffprdir/${pwmsp3}_fp/${Abprefixes[${SLURM_ARRAY_TASK_ID}]}.bed

echo '# -- 3a. TF footprinting preparation has completed - bioMart alias, annotations and data.config prep -- #'

echo '# -- 3b. TF footprinting and creation of signal tracks started -- #'


# JOBID6=$( sbatch -W --dependency=afterok:${JOBID5} xx.sh | awk '{print $4}' ) # JOB6 depends on JOB5 completing successfully
## This will need five jobs - put in a while loop using fpsp

for Efpsp in "${!fpsp@}"; do
  jobidadd=$(echo $Efpsp | grep -Eo '[0-9]')
  jobidadd2=`expr $j + $jobidadd`
  # echo $jobidadd
  # echo $jobidadd2
  JOBID"${jobidadd2}"=$( sbatch -W --dependency=afterok:${JOBID6} "${!Efpsp}"'_TFfp.sh' | awk '{print $4}' ) # JOB7-JOB11
done


################################################################################################################

### 4. Differential analysis of peaks

### NOTE: be careful when considering differential peaks as some may be only offset by a few bases. In this secnario, consider the average number of mapped reads over a window.

## FOR SIMPLE DIFFERENTIAL ANALYSIS OF PEAKS, USE HOMER; SOME CODE HERE: https://dtc-coding-dojo.github.io/main//blog/Analysing_ATAC_and_CHIPseq_data/
## Then use DiffBind to:
  # A. Determine tissue-specific peaks in each species
    # Tissue-specificity of ATAC-seq peaks was determined using DiffBind (https://www.bioconductor.org/packages/release/bioc/ html/DiffBind.html),
    # This provided the peak coordinates for each of the biological replicates of all tissues profiled as input, plus the mapped and shifted sequencing reads (parameters ‘method = DBA_EDGER, bFullLibrarySize = FALSE, bSubControl = FALSE, bTagwise = FALSE’).
    # All peaks identified with a log2 fold change equal or greater than 1 in one tissue compared to all others were selected as tissue-specific.
  # B. Determine tissue-specific peaks between species same tissues e.g. Ab5_L vs Nb5_L
    # you need to find a way to compare different species - use association to orthologous genes?


## ~ INSERT CODE HERE ~ ##

echo '# -- 3b. TF footprinting and creation of signal tracks has completed -- #'

echo '# -- 4. Differential analysis of peaks has started -- #'

JOBID8=$( sbatch -W --dependency=afterok:${JOBID7} XX.sh | awk '{print $4}' ) # JOB4 depends on JOB3 completing successfully

################################################################################################################

echo '# -- 5. Differential analysis of peaks has completed -- #'

### Finish the script
exit 0
